{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, minmax_scale, scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparar los datos como lo haciamos nosotros\n",
    "seed = 42\n",
    "DATASETX = \"./data/prep/HotelReservationsPreparedCleanX.csv\"\n",
    "DATASETY = \"./data/prep/HotelReservationsY.csv\"\n",
    "df_x = pd.read_csv(DATASETX)\n",
    "df_y = pd.read_csv(DATASETY)\n",
    "df = pd.concat([df_x, df_y], axis=1)\n",
    "df = shuffle(df, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparar los datos como el profe\n",
    "ATT_FILE = \"./data/prep/HotelReservationsPreparedCleanX.csv\"\n",
    "LABEL_FILE = \"./data/prep/HotelReservationsY.csv\"\n",
    "\n",
    "TRAIN_RATE=0.8\n",
    "\n",
    "attributes = pd.read_csv(ATT_FILE)\n",
    "label = pd.read_csv(LABEL_FILE)\n",
    "\n",
    "n_instances = attributes.shape[0]\n",
    "n_train = int(n_instances*TRAIN_RATE)\n",
    "n_dev = int((n_instances-n_train)/2)\n",
    "\n",
    "X_train = attributes.values[:n_train]\n",
    "y_train = label.values[:n_train]\n",
    "\n",
    "X_val = attributes.values[n_train:n_train+n_dev]\n",
    "y_val = label.values[n_train:n_train+n_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Chema\\Desktop\\MASTER\\DeepLearning\\DL\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Dividimos el dataframe en train y test en una proporción de 80/20\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(df, df[\u001b[39m\"\u001b[39m\u001b[39mbooking_status\u001b[39m\u001b[39m\"\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mseed)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Dividimos el conjunto de prueba en test y validation en una proporción de 50/50\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test, X_val, y_test, y_val \u001b[39m=\u001b[39m train_test_split(X_test, y_test, test_size\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dividimos el dataframe en train y test en una proporción de 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df[\"booking_status\"], test_size=0.2, random_state=seed)\n",
    "\n",
    "# Dividimos el conjunto de prueba en test y validation en una proporción de 50/50\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = 1\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int (round (X_val.shape[0]/1))\n",
    "print(INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializar hiperparámetros\n",
    "n_epochs = 1000\n",
    "lr = 0.1\n",
    "batch_size = 1024\n",
    "n_neurons_per_hlayer = [2000, 2000, 1000, 1000]\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "lr,\n",
    "decay_steps=100000,\n",
    "decay_rate=0.96,\n",
    "staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepFeedforward\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_29 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 16)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2000)              34000     \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 2000)              8000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 2000)              0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 2000)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2000)              4002000   \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 2000)              8000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 2000)              0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 2000)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1000)              2001000   \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 1000)              4000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 1000)              4000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                10010     \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7072125 (26.98 MB)\n",
      "Trainable params: 7060073 (26.93 MB)\n",
      "Non-trainable params: 12052 (47.08 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Construir el modelo\n",
    "model = keras.Sequential(name=\"DeepFeedforward\")\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape=(INPUTS,), batch_size=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "for neurons in n_neurons_per_hlayer:\n",
    "  model.add(keras.layers.Dense(neurons))\n",
    "  model.add(keras.layers.BatchNormalization())\n",
    "  model.add(keras.layers.Activation(\"relu\"))\n",
    "  model.add(keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(10))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "29/29 [==============================] - 18s 449ms/step - loss: 0.4783 - binary_accuracy: 0.7620 - val_loss: 49.0433 - val_binary_accuracy: 0.4852 - lr: 0.1000\n",
      "Epoch 2/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.4134 - binary_accuracy: 0.8104 - val_loss: 13.9307 - val_binary_accuracy: 0.3791 - lr: 0.1000\n",
      "Epoch 3/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.4040 - binary_accuracy: 0.8168 - val_loss: 3.2899 - val_binary_accuracy: 0.5969 - lr: 0.1000\n",
      "Epoch 4/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.3919 - binary_accuracy: 0.8220 - val_loss: 1.3223 - val_binary_accuracy: 0.6697 - lr: 0.1000\n",
      "Epoch 5/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3906 - binary_accuracy: 0.8220 - val_loss: 1.0243 - val_binary_accuracy: 0.7477 - lr: 0.1000\n",
      "Epoch 6/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.3827 - binary_accuracy: 0.8217 - val_loss: 0.7191 - val_binary_accuracy: 0.7764 - lr: 0.1000\n",
      "Epoch 7/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.3788 - binary_accuracy: 0.8266 - val_loss: 0.9405 - val_binary_accuracy: 0.7676 - lr: 0.1000\n",
      "Epoch 8/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.3726 - binary_accuracy: 0.8258 - val_loss: 0.8647 - val_binary_accuracy: 0.7863 - lr: 0.1000\n",
      "Epoch 9/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.3720 - binary_accuracy: 0.8284 - val_loss: 0.6648 - val_binary_accuracy: 0.7891 - lr: 0.1000\n",
      "Epoch 10/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3666 - binary_accuracy: 0.8279 - val_loss: 0.9316 - val_binary_accuracy: 0.7814 - lr: 0.1000\n",
      "Epoch 11/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.3639 - binary_accuracy: 0.8312 - val_loss: 0.6565 - val_binary_accuracy: 0.7910 - lr: 0.1000\n",
      "Epoch 12/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.3729 - binary_accuracy: 0.8267 - val_loss: 0.7453 - val_binary_accuracy: 0.7883 - lr: 0.1000\n",
      "Epoch 13/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3630 - binary_accuracy: 0.8301 - val_loss: 0.9658 - val_binary_accuracy: 0.7568 - lr: 0.1000\n",
      "Epoch 14/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.3578 - binary_accuracy: 0.8325 - val_loss: 0.7133 - val_binary_accuracy: 0.7714 - lr: 0.1000\n",
      "Epoch 15/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.3586 - binary_accuracy: 0.8310 - val_loss: 0.7419 - val_binary_accuracy: 0.7872 - lr: 0.1000\n",
      "Epoch 16/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.3547 - binary_accuracy: 0.8354 - val_loss: 0.7656 - val_binary_accuracy: 0.7808 - lr: 0.1000\n",
      "Epoch 17/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.3518 - binary_accuracy: 0.8376 - val_loss: 0.6640 - val_binary_accuracy: 0.7907 - lr: 0.1000\n",
      "Epoch 18/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.3513 - binary_accuracy: 0.8366 - val_loss: 0.4850 - val_binary_accuracy: 0.8070 - lr: 0.1000\n",
      "Epoch 19/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.3515 - binary_accuracy: 0.8386 - val_loss: 0.5854 - val_binary_accuracy: 0.8001 - lr: 0.1000\n",
      "Epoch 20/1000\n",
      "29/29 [==============================] - 13s 441ms/step - loss: 0.3498 - binary_accuracy: 0.8377 - val_loss: 0.5107 - val_binary_accuracy: 0.7987 - lr: 0.1000\n",
      "Epoch 21/1000\n",
      "29/29 [==============================] - 13s 435ms/step - loss: 0.3504 - binary_accuracy: 0.8366 - val_loss: 0.6094 - val_binary_accuracy: 0.8015 - lr: 0.1000\n",
      "Epoch 22/1000\n",
      "29/29 [==============================] - 13s 444ms/step - loss: 0.3456 - binary_accuracy: 0.8374 - val_loss: 0.4952 - val_binary_accuracy: 0.8040 - lr: 0.1000\n",
      "Epoch 23/1000\n",
      "29/29 [==============================] - 13s 431ms/step - loss: 0.3454 - binary_accuracy: 0.8385 - val_loss: 0.6253 - val_binary_accuracy: 0.7910 - lr: 0.1000\n",
      "Epoch 24/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.3459 - binary_accuracy: 0.8380 - val_loss: 0.4817 - val_binary_accuracy: 0.8048 - lr: 0.1000\n",
      "Epoch 25/1000\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 0.3409 - binary_accuracy: 0.8424 - val_loss: 0.5328 - val_binary_accuracy: 0.7940 - lr: 0.1000\n",
      "Epoch 26/1000\n",
      "29/29 [==============================] - 14s 480ms/step - loss: 0.3404 - binary_accuracy: 0.8421 - val_loss: 0.4066 - val_binary_accuracy: 0.8197 - lr: 0.1000\n",
      "Epoch 27/1000\n",
      "29/29 [==============================] - 13s 443ms/step - loss: 0.3410 - binary_accuracy: 0.8425 - val_loss: 0.4991 - val_binary_accuracy: 0.8062 - lr: 0.1000\n",
      "Epoch 28/1000\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 0.3419 - binary_accuracy: 0.8435 - val_loss: 0.4976 - val_binary_accuracy: 0.8056 - lr: 0.1000\n",
      "Epoch 29/1000\n",
      "29/29 [==============================] - 13s 444ms/step - loss: 0.3417 - binary_accuracy: 0.8420 - val_loss: 0.4223 - val_binary_accuracy: 0.8213 - lr: 0.1000\n",
      "Epoch 30/1000\n",
      "29/29 [==============================] - 13s 447ms/step - loss: 0.3375 - binary_accuracy: 0.8451 - val_loss: 0.5500 - val_binary_accuracy: 0.7794 - lr: 0.1000\n",
      "Epoch 31/1000\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.3375 - binary_accuracy: 0.8442 - val_loss: 0.4878 - val_binary_accuracy: 0.8051 - lr: 0.1000\n",
      "Epoch 32/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.3356 - binary_accuracy: 0.8439 - val_loss: 0.5853 - val_binary_accuracy: 0.7938 - lr: 0.1000\n",
      "Epoch 33/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.3371 - binary_accuracy: 0.8435 - val_loss: 0.5363 - val_binary_accuracy: 0.8117 - lr: 0.1000\n",
      "Epoch 34/1000\n",
      "29/29 [==============================] - 13s 447ms/step - loss: 0.3367 - binary_accuracy: 0.8428 - val_loss: 0.4616 - val_binary_accuracy: 0.8065 - lr: 0.1000\n",
      "Epoch 35/1000\n",
      "29/29 [==============================] - 13s 445ms/step - loss: 0.3368 - binary_accuracy: 0.8458 - val_loss: 0.4309 - val_binary_accuracy: 0.8172 - lr: 0.1000\n",
      "Epoch 36/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.3369 - binary_accuracy: 0.8446 - val_loss: 0.4473 - val_binary_accuracy: 0.8219 - lr: 0.1000\n",
      "Epoch 37/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.3328 - binary_accuracy: 0.8460 - val_loss: 0.4226 - val_binary_accuracy: 0.8296 - lr: 0.1000\n",
      "Epoch 38/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.3336 - binary_accuracy: 0.8479 - val_loss: 0.4488 - val_binary_accuracy: 0.8175 - lr: 0.1000\n",
      "Epoch 39/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.3316 - binary_accuracy: 0.8475 - val_loss: 0.4363 - val_binary_accuracy: 0.8252 - lr: 0.1000\n",
      "Epoch 40/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.3323 - binary_accuracy: 0.8487 - val_loss: 0.4042 - val_binary_accuracy: 0.8277 - lr: 0.1000\n",
      "Epoch 41/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.3294 - binary_accuracy: 0.8486 - val_loss: 0.3728 - val_binary_accuracy: 0.8351 - lr: 0.1000\n",
      "Epoch 42/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.3313 - binary_accuracy: 0.8466 - val_loss: 0.3973 - val_binary_accuracy: 0.8329 - lr: 0.1000\n",
      "Epoch 43/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.3281 - binary_accuracy: 0.8478 - val_loss: 0.3652 - val_binary_accuracy: 0.8371 - lr: 0.1000\n",
      "Epoch 44/1000\n",
      "29/29 [==============================] - 11s 389ms/step - loss: 0.3290 - binary_accuracy: 0.8488 - val_loss: 0.4459 - val_binary_accuracy: 0.8249 - lr: 0.1000\n",
      "Epoch 45/1000\n",
      "29/29 [==============================] - 11s 389ms/step - loss: 0.3298 - binary_accuracy: 0.8479 - val_loss: 0.4417 - val_binary_accuracy: 0.8291 - lr: 0.1000\n",
      "Epoch 46/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.3291 - binary_accuracy: 0.8493 - val_loss: 0.3988 - val_binary_accuracy: 0.8302 - lr: 0.1000\n",
      "Epoch 47/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.3247 - binary_accuracy: 0.8519 - val_loss: 0.4617 - val_binary_accuracy: 0.8213 - lr: 0.1000\n",
      "Epoch 48/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.3266 - binary_accuracy: 0.8478 - val_loss: 0.3895 - val_binary_accuracy: 0.8194 - lr: 0.1000\n",
      "Epoch 49/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.3306 - binary_accuracy: 0.8494 - val_loss: 0.3635 - val_binary_accuracy: 0.8360 - lr: 0.1000\n",
      "Epoch 50/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3258 - binary_accuracy: 0.8517 - val_loss: 0.4065 - val_binary_accuracy: 0.8310 - lr: 0.1000\n",
      "Epoch 51/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.3241 - binary_accuracy: 0.8507 - val_loss: 0.3860 - val_binary_accuracy: 0.8304 - lr: 0.1000\n",
      "Epoch 52/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3223 - binary_accuracy: 0.8527 - val_loss: 0.3676 - val_binary_accuracy: 0.8382 - lr: 0.1000\n",
      "Epoch 53/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3234 - binary_accuracy: 0.8512 - val_loss: 0.3533 - val_binary_accuracy: 0.8376 - lr: 0.1000\n",
      "Epoch 54/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.3211 - binary_accuracy: 0.8547 - val_loss: 0.4067 - val_binary_accuracy: 0.8211 - lr: 0.1000\n",
      "Epoch 55/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.3228 - binary_accuracy: 0.8535 - val_loss: 0.3931 - val_binary_accuracy: 0.8318 - lr: 0.1000\n",
      "Epoch 56/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.3203 - binary_accuracy: 0.8535 - val_loss: 0.3916 - val_binary_accuracy: 0.8326 - lr: 0.1000\n",
      "Epoch 57/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.3185 - binary_accuracy: 0.8556 - val_loss: 0.4120 - val_binary_accuracy: 0.8263 - lr: 0.1000\n",
      "Epoch 58/1000\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 0.3217 - binary_accuracy: 0.8524 - val_loss: 0.4035 - val_binary_accuracy: 0.8271 - lr: 0.1000\n",
      "Epoch 59/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3222 - binary_accuracy: 0.8533 - val_loss: 0.3712 - val_binary_accuracy: 0.8379 - lr: 0.1000\n",
      "Epoch 60/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.3187 - binary_accuracy: 0.8557 - val_loss: 0.3488 - val_binary_accuracy: 0.8348 - lr: 0.1000\n",
      "Epoch 61/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.3187 - binary_accuracy: 0.8559 - val_loss: 0.3365 - val_binary_accuracy: 0.8453 - lr: 0.1000\n",
      "Epoch 62/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3182 - binary_accuracy: 0.8555 - val_loss: 0.3849 - val_binary_accuracy: 0.8362 - lr: 0.1000\n",
      "Epoch 63/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3158 - binary_accuracy: 0.8554 - val_loss: 0.4049 - val_binary_accuracy: 0.8354 - lr: 0.1000\n",
      "Epoch 64/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.3174 - binary_accuracy: 0.8550 - val_loss: 0.3492 - val_binary_accuracy: 0.8426 - lr: 0.1000\n",
      "Epoch 65/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3149 - binary_accuracy: 0.8567 - val_loss: 0.3899 - val_binary_accuracy: 0.8321 - lr: 0.1000\n",
      "Epoch 66/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.3198 - binary_accuracy: 0.8560 - val_loss: 0.4121 - val_binary_accuracy: 0.8269 - lr: 0.1000\n",
      "Epoch 67/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.3150 - binary_accuracy: 0.8568 - val_loss: 0.3870 - val_binary_accuracy: 0.8365 - lr: 0.1000\n",
      "Epoch 68/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.3158 - binary_accuracy: 0.8565 - val_loss: 0.3518 - val_binary_accuracy: 0.8417 - lr: 0.1000\n",
      "Epoch 69/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.3148 - binary_accuracy: 0.8570 - val_loss: 0.3568 - val_binary_accuracy: 0.8423 - lr: 0.1000\n",
      "Epoch 70/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.3162 - binary_accuracy: 0.8568 - val_loss: 0.3604 - val_binary_accuracy: 0.8401 - lr: 0.1000\n",
      "Epoch 71/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3135 - binary_accuracy: 0.8568 - val_loss: 0.3397 - val_binary_accuracy: 0.8508 - lr: 0.1000\n",
      "Epoch 72/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.3135 - binary_accuracy: 0.8576 - val_loss: 0.3859 - val_binary_accuracy: 0.8313 - lr: 0.1000\n",
      "Epoch 73/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3139 - binary_accuracy: 0.8579 - val_loss: 0.3822 - val_binary_accuracy: 0.8354 - lr: 0.1000\n",
      "Epoch 74/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.3119 - binary_accuracy: 0.8589 - val_loss: 0.3397 - val_binary_accuracy: 0.8475 - lr: 0.1000\n",
      "Epoch 75/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.3144 - binary_accuracy: 0.8568 - val_loss: 0.3705 - val_binary_accuracy: 0.8354 - lr: 0.1000\n",
      "Epoch 76/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3129 - binary_accuracy: 0.8590 - val_loss: 0.3519 - val_binary_accuracy: 0.8448 - lr: 0.1000\n",
      "Epoch 77/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.3128 - binary_accuracy: 0.8578 - val_loss: 0.4761 - val_binary_accuracy: 0.8172 - lr: 0.1000\n",
      "Epoch 78/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3088 - binary_accuracy: 0.8604 - val_loss: 0.3694 - val_binary_accuracy: 0.8412 - lr: 0.1000\n",
      "Epoch 79/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.3119 - binary_accuracy: 0.8586 - val_loss: 0.3689 - val_binary_accuracy: 0.8379 - lr: 0.1000\n",
      "Epoch 80/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.3080 - binary_accuracy: 0.8603 - val_loss: 0.3378 - val_binary_accuracy: 0.8478 - lr: 0.1000\n",
      "Epoch 81/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.3110 - binary_accuracy: 0.8595 - val_loss: 0.3478 - val_binary_accuracy: 0.8484 - lr: 0.1000\n",
      "Epoch 82/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.3045 - binary_accuracy: 0.8626 - val_loss: 0.3386 - val_binary_accuracy: 0.8484 - lr: 0.0500\n",
      "Epoch 83/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2995 - binary_accuracy: 0.8646 - val_loss: 0.3165 - val_binary_accuracy: 0.8541 - lr: 0.0500\n",
      "Epoch 84/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2987 - binary_accuracy: 0.8658 - val_loss: 0.3127 - val_binary_accuracy: 0.8547 - lr: 0.0500\n",
      "Epoch 85/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.3001 - binary_accuracy: 0.8641 - val_loss: 0.3168 - val_binary_accuracy: 0.8533 - lr: 0.0500\n",
      "Epoch 86/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2963 - binary_accuracy: 0.8669 - val_loss: 0.3088 - val_binary_accuracy: 0.8580 - lr: 0.0500\n",
      "Epoch 87/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2960 - binary_accuracy: 0.8666 - val_loss: 0.3091 - val_binary_accuracy: 0.8555 - lr: 0.0500\n",
      "Epoch 88/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2981 - binary_accuracy: 0.8653 - val_loss: 0.3042 - val_binary_accuracy: 0.8621 - lr: 0.0500\n",
      "Epoch 89/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2945 - binary_accuracy: 0.8658 - val_loss: 0.3040 - val_binary_accuracy: 0.8638 - lr: 0.0500\n",
      "Epoch 90/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2940 - binary_accuracy: 0.8690 - val_loss: 0.3080 - val_binary_accuracy: 0.8602 - lr: 0.0500\n",
      "Epoch 91/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2969 - binary_accuracy: 0.8648 - val_loss: 0.3054 - val_binary_accuracy: 0.8621 - lr: 0.0500\n",
      "Epoch 92/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2935 - binary_accuracy: 0.8673 - val_loss: 0.3059 - val_binary_accuracy: 0.8599 - lr: 0.0500\n",
      "Epoch 93/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.2944 - binary_accuracy: 0.8666 - val_loss: 0.3070 - val_binary_accuracy: 0.8583 - lr: 0.0500\n",
      "Epoch 94/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2930 - binary_accuracy: 0.8667 - val_loss: 0.3049 - val_binary_accuracy: 0.8638 - lr: 0.0500\n",
      "Epoch 95/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.2943 - binary_accuracy: 0.8669 - val_loss: 0.3087 - val_binary_accuracy: 0.8599 - lr: 0.0500\n",
      "Epoch 96/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2941 - binary_accuracy: 0.8673 - val_loss: 0.3040 - val_binary_accuracy: 0.8621 - lr: 0.0500\n",
      "Epoch 97/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2921 - binary_accuracy: 0.8694 - val_loss: 0.2983 - val_binary_accuracy: 0.8666 - lr: 0.0500\n",
      "Epoch 98/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2874 - binary_accuracy: 0.8712 - val_loss: 0.3064 - val_binary_accuracy: 0.8572 - lr: 0.0500\n",
      "Epoch 99/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2948 - binary_accuracy: 0.8673 - val_loss: 0.3008 - val_binary_accuracy: 0.8641 - lr: 0.0500\n",
      "Epoch 100/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2911 - binary_accuracy: 0.8685 - val_loss: 0.3028 - val_binary_accuracy: 0.8655 - lr: 0.0500\n",
      "Epoch 101/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2908 - binary_accuracy: 0.8685 - val_loss: 0.3011 - val_binary_accuracy: 0.8682 - lr: 0.0500\n",
      "Epoch 102/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2918 - binary_accuracy: 0.8685 - val_loss: 0.2974 - val_binary_accuracy: 0.8679 - lr: 0.0500\n",
      "Epoch 103/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2878 - binary_accuracy: 0.8724 - val_loss: 0.2995 - val_binary_accuracy: 0.8688 - lr: 0.0500\n",
      "Epoch 104/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2908 - binary_accuracy: 0.8695 - val_loss: 0.2985 - val_binary_accuracy: 0.8632 - lr: 0.0500\n",
      "Epoch 105/1000\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 0.2901 - binary_accuracy: 0.8696 - val_loss: 0.3007 - val_binary_accuracy: 0.8685 - lr: 0.0500\n",
      "Epoch 106/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2876 - binary_accuracy: 0.8699 - val_loss: 0.2972 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 107/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2891 - binary_accuracy: 0.8710 - val_loss: 0.2976 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 108/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2884 - binary_accuracy: 0.8710 - val_loss: 0.3019 - val_binary_accuracy: 0.8660 - lr: 0.0500\n",
      "Epoch 109/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2908 - binary_accuracy: 0.8700 - val_loss: 0.3034 - val_binary_accuracy: 0.8663 - lr: 0.0500\n",
      "Epoch 110/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2893 - binary_accuracy: 0.8700 - val_loss: 0.3033 - val_binary_accuracy: 0.8660 - lr: 0.0500\n",
      "Epoch 111/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2877 - binary_accuracy: 0.8701 - val_loss: 0.2983 - val_binary_accuracy: 0.8701 - lr: 0.0500\n",
      "Epoch 112/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2887 - binary_accuracy: 0.8713 - val_loss: 0.2973 - val_binary_accuracy: 0.8701 - lr: 0.0500\n",
      "Epoch 113/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2869 - binary_accuracy: 0.8716 - val_loss: 0.2965 - val_binary_accuracy: 0.8690 - lr: 0.0500\n",
      "Epoch 114/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.2871 - binary_accuracy: 0.8716 - val_loss: 0.2989 - val_binary_accuracy: 0.8657 - lr: 0.0500\n",
      "Epoch 115/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2873 - binary_accuracy: 0.8726 - val_loss: 0.3000 - val_binary_accuracy: 0.8674 - lr: 0.0500\n",
      "Epoch 116/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2854 - binary_accuracy: 0.8730 - val_loss: 0.2986 - val_binary_accuracy: 0.8682 - lr: 0.0500\n",
      "Epoch 117/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2869 - binary_accuracy: 0.8717 - val_loss: 0.2969 - val_binary_accuracy: 0.8671 - lr: 0.0500\n",
      "Epoch 118/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2865 - binary_accuracy: 0.8708 - val_loss: 0.3002 - val_binary_accuracy: 0.8663 - lr: 0.0500\n",
      "Epoch 119/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2864 - binary_accuracy: 0.8709 - val_loss: 0.2982 - val_binary_accuracy: 0.8715 - lr: 0.0500\n",
      "Epoch 120/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2875 - binary_accuracy: 0.8712 - val_loss: 0.2975 - val_binary_accuracy: 0.8668 - lr: 0.0500\n",
      "Epoch 121/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2841 - binary_accuracy: 0.8723 - val_loss: 0.3000 - val_binary_accuracy: 0.8677 - lr: 0.0500\n",
      "Epoch 122/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2832 - binary_accuracy: 0.8734 - val_loss: 0.2981 - val_binary_accuracy: 0.8679 - lr: 0.0500\n",
      "Epoch 123/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2832 - binary_accuracy: 0.8716 - val_loss: 0.2945 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 124/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2834 - binary_accuracy: 0.8736 - val_loss: 0.3052 - val_binary_accuracy: 0.8652 - lr: 0.0500\n",
      "Epoch 125/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2883 - binary_accuracy: 0.8728 - val_loss: 0.2975 - val_binary_accuracy: 0.8723 - lr: 0.0500\n",
      "Epoch 126/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2832 - binary_accuracy: 0.8735 - val_loss: 0.2963 - val_binary_accuracy: 0.8685 - lr: 0.0500\n",
      "Epoch 127/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2856 - binary_accuracy: 0.8727 - val_loss: 0.3010 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 128/1000\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 0.2858 - binary_accuracy: 0.8728 - val_loss: 0.2986 - val_binary_accuracy: 0.8668 - lr: 0.0500\n",
      "Epoch 129/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2832 - binary_accuracy: 0.8731 - val_loss: 0.3037 - val_binary_accuracy: 0.8605 - lr: 0.0500\n",
      "Epoch 130/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2822 - binary_accuracy: 0.8738 - val_loss: 0.3000 - val_binary_accuracy: 0.8699 - lr: 0.0500\n",
      "Epoch 131/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2815 - binary_accuracy: 0.8753 - val_loss: 0.2991 - val_binary_accuracy: 0.8693 - lr: 0.0500\n",
      "Epoch 132/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2818 - binary_accuracy: 0.8738 - val_loss: 0.2945 - val_binary_accuracy: 0.8715 - lr: 0.0500\n",
      "Epoch 133/1000\n",
      "29/29 [==============================] - 13s 436ms/step - loss: 0.2831 - binary_accuracy: 0.8731 - val_loss: 0.2948 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 134/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2813 - binary_accuracy: 0.8738 - val_loss: 0.2981 - val_binary_accuracy: 0.8701 - lr: 0.0500\n",
      "Epoch 135/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2834 - binary_accuracy: 0.8713 - val_loss: 0.2937 - val_binary_accuracy: 0.8671 - lr: 0.0500\n",
      "Epoch 136/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2819 - binary_accuracy: 0.8742 - val_loss: 0.2906 - val_binary_accuracy: 0.8721 - lr: 0.0500\n",
      "Epoch 137/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2785 - binary_accuracy: 0.8759 - val_loss: 0.2973 - val_binary_accuracy: 0.8710 - lr: 0.0500\n",
      "Epoch 138/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2833 - binary_accuracy: 0.8726 - val_loss: 0.2962 - val_binary_accuracy: 0.8688 - lr: 0.0500\n",
      "Epoch 139/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2789 - binary_accuracy: 0.8762 - val_loss: 0.3084 - val_binary_accuracy: 0.8580 - lr: 0.0500\n",
      "Epoch 140/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2821 - binary_accuracy: 0.8739 - val_loss: 0.3005 - val_binary_accuracy: 0.8682 - lr: 0.0500\n",
      "Epoch 141/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2818 - binary_accuracy: 0.8733 - val_loss: 0.2942 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 142/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2798 - binary_accuracy: 0.8742 - val_loss: 0.2946 - val_binary_accuracy: 0.8682 - lr: 0.0500\n",
      "Epoch 143/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2793 - binary_accuracy: 0.8751 - val_loss: 0.2955 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 144/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2815 - binary_accuracy: 0.8740 - val_loss: 0.3013 - val_binary_accuracy: 0.8699 - lr: 0.0500\n",
      "Epoch 145/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2802 - binary_accuracy: 0.8752 - val_loss: 0.2944 - val_binary_accuracy: 0.8696 - lr: 0.0500\n",
      "Epoch 146/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2800 - binary_accuracy: 0.8754 - val_loss: 0.3000 - val_binary_accuracy: 0.8710 - lr: 0.0500\n",
      "Epoch 147/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2817 - binary_accuracy: 0.8754 - val_loss: 0.3005 - val_binary_accuracy: 0.8715 - lr: 0.0500\n",
      "Epoch 148/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2758 - binary_accuracy: 0.8762 - val_loss: 0.2967 - val_binary_accuracy: 0.8693 - lr: 0.0500\n",
      "Epoch 149/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.2803 - binary_accuracy: 0.8744 - val_loss: 0.2981 - val_binary_accuracy: 0.8704 - lr: 0.0500\n",
      "Epoch 150/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2783 - binary_accuracy: 0.8746 - val_loss: 0.2936 - val_binary_accuracy: 0.8701 - lr: 0.0500\n",
      "Epoch 151/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.2789 - binary_accuracy: 0.8759 - val_loss: 0.3008 - val_binary_accuracy: 0.8693 - lr: 0.0500\n",
      "Epoch 152/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.2778 - binary_accuracy: 0.8759 - val_loss: 0.2985 - val_binary_accuracy: 0.8690 - lr: 0.0500\n",
      "Epoch 153/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2776 - binary_accuracy: 0.8749 - val_loss: 0.2935 - val_binary_accuracy: 0.8704 - lr: 0.0500\n",
      "Epoch 154/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2788 - binary_accuracy: 0.8744 - val_loss: 0.2950 - val_binary_accuracy: 0.8693 - lr: 0.0500\n",
      "Epoch 155/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2797 - binary_accuracy: 0.8748 - val_loss: 0.2906 - val_binary_accuracy: 0.8712 - lr: 0.0500\n",
      "Epoch 156/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2783 - binary_accuracy: 0.8763 - val_loss: 0.2954 - val_binary_accuracy: 0.8712 - lr: 0.0500\n",
      "Epoch 157/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2756 - binary_accuracy: 0.8779 - val_loss: 0.2899 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 158/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2717 - binary_accuracy: 0.8787 - val_loss: 0.2895 - val_binary_accuracy: 0.8726 - lr: 0.0250\n",
      "Epoch 159/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2699 - binary_accuracy: 0.8790 - val_loss: 0.2884 - val_binary_accuracy: 0.8751 - lr: 0.0250\n",
      "Epoch 160/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2692 - binary_accuracy: 0.8789 - val_loss: 0.2898 - val_binary_accuracy: 0.8732 - lr: 0.0250\n",
      "Epoch 161/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2704 - binary_accuracy: 0.8794 - val_loss: 0.2880 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 162/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2672 - binary_accuracy: 0.8811 - val_loss: 0.2892 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 163/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2692 - binary_accuracy: 0.8778 - val_loss: 0.2894 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 164/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2672 - binary_accuracy: 0.8806 - val_loss: 0.2902 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 165/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2682 - binary_accuracy: 0.8806 - val_loss: 0.2867 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 166/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2677 - binary_accuracy: 0.8820 - val_loss: 0.2890 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 167/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2684 - binary_accuracy: 0.8798 - val_loss: 0.2851 - val_binary_accuracy: 0.8737 - lr: 0.0250\n",
      "Epoch 168/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2691 - binary_accuracy: 0.8803 - val_loss: 0.2884 - val_binary_accuracy: 0.8732 - lr: 0.0250\n",
      "Epoch 169/1000\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 0.2676 - binary_accuracy: 0.8797 - val_loss: 0.2893 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 170/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2651 - binary_accuracy: 0.8819 - val_loss: 0.2876 - val_binary_accuracy: 0.8765 - lr: 0.0250\n",
      "Epoch 171/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2646 - binary_accuracy: 0.8808 - val_loss: 0.2873 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 172/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2689 - binary_accuracy: 0.8794 - val_loss: 0.2876 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 173/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2679 - binary_accuracy: 0.8807 - val_loss: 0.2863 - val_binary_accuracy: 0.8751 - lr: 0.0250\n",
      "Epoch 174/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2667 - binary_accuracy: 0.8798 - val_loss: 0.2854 - val_binary_accuracy: 0.8718 - lr: 0.0250\n",
      "Epoch 175/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2665 - binary_accuracy: 0.8810 - val_loss: 0.2862 - val_binary_accuracy: 0.8721 - lr: 0.0250\n",
      "Epoch 176/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2666 - binary_accuracy: 0.8810 - val_loss: 0.2862 - val_binary_accuracy: 0.8740 - lr: 0.0250\n",
      "Epoch 177/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2648 - binary_accuracy: 0.8804 - val_loss: 0.2855 - val_binary_accuracy: 0.8746 - lr: 0.0250\n",
      "Epoch 178/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.2658 - binary_accuracy: 0.8791 - val_loss: 0.2875 - val_binary_accuracy: 0.8732 - lr: 0.0250\n",
      "Epoch 179/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2655 - binary_accuracy: 0.8818 - val_loss: 0.2876 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 180/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2635 - binary_accuracy: 0.8818 - val_loss: 0.2859 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 181/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2617 - binary_accuracy: 0.8834 - val_loss: 0.2857 - val_binary_accuracy: 0.8734 - lr: 0.0250\n",
      "Epoch 182/1000\n",
      "29/29 [==============================] - 11s 397ms/step - loss: 0.2641 - binary_accuracy: 0.8812 - val_loss: 0.2861 - val_binary_accuracy: 0.8754 - lr: 0.0250\n",
      "Epoch 183/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2639 - binary_accuracy: 0.8816 - val_loss: 0.2833 - val_binary_accuracy: 0.8762 - lr: 0.0250\n",
      "Epoch 184/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2655 - binary_accuracy: 0.8814 - val_loss: 0.2890 - val_binary_accuracy: 0.8740 - lr: 0.0250\n",
      "Epoch 185/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2632 - binary_accuracy: 0.8824 - val_loss: 0.2889 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 186/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.2638 - binary_accuracy: 0.8811 - val_loss: 0.2909 - val_binary_accuracy: 0.8721 - lr: 0.0250\n",
      "Epoch 187/1000\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 0.2649 - binary_accuracy: 0.8816 - val_loss: 0.2859 - val_binary_accuracy: 0.8732 - lr: 0.0250\n",
      "Epoch 188/1000\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.2645 - binary_accuracy: 0.8810 - val_loss: 0.2877 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 189/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.2639 - binary_accuracy: 0.8813 - val_loss: 0.2856 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 190/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2651 - binary_accuracy: 0.8806 - val_loss: 0.2863 - val_binary_accuracy: 0.8737 - lr: 0.0250\n",
      "Epoch 191/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.2623 - binary_accuracy: 0.8818 - val_loss: 0.2860 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 192/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.2623 - binary_accuracy: 0.8819 - val_loss: 0.2854 - val_binary_accuracy: 0.8734 - lr: 0.0250\n",
      "Epoch 193/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.2637 - binary_accuracy: 0.8809 - val_loss: 0.2837 - val_binary_accuracy: 0.8751 - lr: 0.0250\n",
      "Epoch 194/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2627 - binary_accuracy: 0.8825 - val_loss: 0.2875 - val_binary_accuracy: 0.8759 - lr: 0.0250\n",
      "Epoch 195/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2627 - binary_accuracy: 0.8847 - val_loss: 0.2855 - val_binary_accuracy: 0.8751 - lr: 0.0250\n",
      "Epoch 196/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2629 - binary_accuracy: 0.8812 - val_loss: 0.2869 - val_binary_accuracy: 0.8751 - lr: 0.0250\n",
      "Epoch 197/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2603 - binary_accuracy: 0.8826 - val_loss: 0.2858 - val_binary_accuracy: 0.8726 - lr: 0.0250\n",
      "Epoch 198/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2622 - binary_accuracy: 0.8826 - val_loss: 0.2832 - val_binary_accuracy: 0.8757 - lr: 0.0250\n",
      "Epoch 199/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2603 - binary_accuracy: 0.8834 - val_loss: 0.2867 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 200/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2611 - binary_accuracy: 0.8825 - val_loss: 0.2831 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 201/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2597 - binary_accuracy: 0.8843 - val_loss: 0.2850 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 202/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2603 - binary_accuracy: 0.8847 - val_loss: 0.2869 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 203/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2632 - binary_accuracy: 0.8822 - val_loss: 0.2870 - val_binary_accuracy: 0.8721 - lr: 0.0250\n",
      "Epoch 204/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2589 - binary_accuracy: 0.8847 - val_loss: 0.2837 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 205/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2593 - binary_accuracy: 0.8829 - val_loss: 0.2899 - val_binary_accuracy: 0.8732 - lr: 0.0250\n",
      "Epoch 206/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2606 - binary_accuracy: 0.8818 - val_loss: 0.2835 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 207/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2604 - binary_accuracy: 0.8838 - val_loss: 0.2851 - val_binary_accuracy: 0.8726 - lr: 0.0250\n",
      "Epoch 208/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2615 - binary_accuracy: 0.8847 - val_loss: 0.2881 - val_binary_accuracy: 0.8740 - lr: 0.0250\n",
      "Epoch 209/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2627 - binary_accuracy: 0.8829 - val_loss: 0.2886 - val_binary_accuracy: 0.8710 - lr: 0.0250\n",
      "Epoch 210/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2610 - binary_accuracy: 0.8829 - val_loss: 0.2829 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 211/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2607 - binary_accuracy: 0.8837 - val_loss: 0.2849 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 212/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2600 - binary_accuracy: 0.8834 - val_loss: 0.2849 - val_binary_accuracy: 0.8718 - lr: 0.0250\n",
      "Epoch 213/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2554 - binary_accuracy: 0.8851 - val_loss: 0.2877 - val_binary_accuracy: 0.8718 - lr: 0.0250\n",
      "Epoch 214/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2567 - binary_accuracy: 0.8848 - val_loss: 0.2833 - val_binary_accuracy: 0.8770 - lr: 0.0250\n",
      "Epoch 215/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2606 - binary_accuracy: 0.8835 - val_loss: 0.2870 - val_binary_accuracy: 0.8729 - lr: 0.0250\n",
      "Epoch 216/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2560 - binary_accuracy: 0.8863 - val_loss: 0.2848 - val_binary_accuracy: 0.8721 - lr: 0.0250\n",
      "Epoch 217/1000\n",
      "29/29 [==============================] - 13s 452ms/step - loss: 0.2563 - binary_accuracy: 0.8865 - val_loss: 0.2890 - val_binary_accuracy: 0.8718 - lr: 0.0250\n",
      "Epoch 218/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2576 - binary_accuracy: 0.8852 - val_loss: 0.2838 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 219/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2612 - binary_accuracy: 0.8833 - val_loss: 0.2836 - val_binary_accuracy: 0.8754 - lr: 0.0250\n",
      "Epoch 220/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2602 - binary_accuracy: 0.8850 - val_loss: 0.2843 - val_binary_accuracy: 0.8762 - lr: 0.0250\n",
      "Epoch 221/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2593 - binary_accuracy: 0.8839 - val_loss: 0.2882 - val_binary_accuracy: 0.8734 - lr: 0.0250\n",
      "Epoch 222/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2579 - binary_accuracy: 0.8845 - val_loss: 0.2847 - val_binary_accuracy: 0.8759 - lr: 0.0250\n",
      "Epoch 223/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2581 - binary_accuracy: 0.8825 - val_loss: 0.2874 - val_binary_accuracy: 0.8776 - lr: 0.0250\n",
      "Epoch 224/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2571 - binary_accuracy: 0.8850 - val_loss: 0.2841 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 225/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2610 - binary_accuracy: 0.8834 - val_loss: 0.2831 - val_binary_accuracy: 0.8757 - lr: 0.0250\n",
      "Epoch 226/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2595 - binary_accuracy: 0.8841 - val_loss: 0.2858 - val_binary_accuracy: 0.8737 - lr: 0.0250\n",
      "Epoch 227/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2585 - binary_accuracy: 0.8840 - val_loss: 0.2870 - val_binary_accuracy: 0.8754 - lr: 0.0250\n",
      "Epoch 228/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2545 - binary_accuracy: 0.8858 - val_loss: 0.2864 - val_binary_accuracy: 0.8743 - lr: 0.0250\n",
      "Epoch 229/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2565 - binary_accuracy: 0.8844 - val_loss: 0.2897 - val_binary_accuracy: 0.8723 - lr: 0.0250\n",
      "Epoch 230/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2542 - binary_accuracy: 0.8855 - val_loss: 0.2878 - val_binary_accuracy: 0.8748 - lr: 0.0250\n",
      "Epoch 231/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2548 - binary_accuracy: 0.8850 - val_loss: 0.2880 - val_binary_accuracy: 0.8765 - lr: 0.0125\n",
      "Epoch 232/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2519 - binary_accuracy: 0.8875 - val_loss: 0.2869 - val_binary_accuracy: 0.8743 - lr: 0.0125\n",
      "Epoch 233/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2552 - binary_accuracy: 0.8852 - val_loss: 0.2880 - val_binary_accuracy: 0.8757 - lr: 0.0125\n",
      "Epoch 234/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2545 - binary_accuracy: 0.8851 - val_loss: 0.2881 - val_binary_accuracy: 0.8757 - lr: 0.0125\n",
      "Epoch 235/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2514 - binary_accuracy: 0.8882 - val_loss: 0.2856 - val_binary_accuracy: 0.8743 - lr: 0.0125\n",
      "Epoch 236/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2540 - binary_accuracy: 0.8862 - val_loss: 0.2852 - val_binary_accuracy: 0.8729 - lr: 0.0125\n",
      "Epoch 237/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2504 - binary_accuracy: 0.8883 - val_loss: 0.2865 - val_binary_accuracy: 0.8746 - lr: 0.0125\n",
      "Epoch 238/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2534 - binary_accuracy: 0.8864 - val_loss: 0.2851 - val_binary_accuracy: 0.8740 - lr: 0.0125\n",
      "Epoch 239/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2515 - binary_accuracy: 0.8882 - val_loss: 0.2857 - val_binary_accuracy: 0.8773 - lr: 0.0125\n",
      "Epoch 240/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2531 - binary_accuracy: 0.8879 - val_loss: 0.2855 - val_binary_accuracy: 0.8768 - lr: 0.0125\n",
      "Epoch 241/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2509 - binary_accuracy: 0.8878 - val_loss: 0.2857 - val_binary_accuracy: 0.8765 - lr: 0.0125\n",
      "Epoch 242/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2495 - binary_accuracy: 0.8878 - val_loss: 0.2847 - val_binary_accuracy: 0.8768 - lr: 0.0125\n",
      "Epoch 243/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2509 - binary_accuracy: 0.8873 - val_loss: 0.2859 - val_binary_accuracy: 0.8748 - lr: 0.0125\n",
      "Epoch 244/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2501 - binary_accuracy: 0.8856 - val_loss: 0.2859 - val_binary_accuracy: 0.8770 - lr: 0.0125\n",
      "Epoch 245/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2500 - binary_accuracy: 0.8869 - val_loss: 0.2873 - val_binary_accuracy: 0.8765 - lr: 0.0125\n",
      "Epoch 246/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2490 - binary_accuracy: 0.8887 - val_loss: 0.2874 - val_binary_accuracy: 0.8765 - lr: 0.0125\n",
      "Epoch 247/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2501 - binary_accuracy: 0.8891 - val_loss: 0.2863 - val_binary_accuracy: 0.8751 - lr: 0.0125\n",
      "Epoch 248/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2495 - binary_accuracy: 0.8873 - val_loss: 0.2878 - val_binary_accuracy: 0.8759 - lr: 0.0125\n",
      "Epoch 249/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2486 - binary_accuracy: 0.8881 - val_loss: 0.2870 - val_binary_accuracy: 0.8759 - lr: 0.0125\n",
      "Epoch 250/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2493 - binary_accuracy: 0.8878 - val_loss: 0.2883 - val_binary_accuracy: 0.8757 - lr: 0.0125\n",
      "Epoch 251/1000\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 0.2479 - binary_accuracy: 0.8893 - val_loss: 0.2866 - val_binary_accuracy: 0.8765 - lr: 0.0063\n",
      "Epoch 252/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2474 - binary_accuracy: 0.8892 - val_loss: 0.2863 - val_binary_accuracy: 0.8773 - lr: 0.0063\n",
      "Epoch 253/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2463 - binary_accuracy: 0.8889 - val_loss: 0.2861 - val_binary_accuracy: 0.8773 - lr: 0.0063\n",
      "Epoch 254/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2459 - binary_accuracy: 0.8898 - val_loss: 0.2871 - val_binary_accuracy: 0.8759 - lr: 0.0063\n",
      "Epoch 255/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2482 - binary_accuracy: 0.8900 - val_loss: 0.2877 - val_binary_accuracy: 0.8776 - lr: 0.0063\n",
      "Epoch 256/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2477 - binary_accuracy: 0.8895 - val_loss: 0.2878 - val_binary_accuracy: 0.8765 - lr: 0.0063\n",
      "Epoch 257/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2458 - binary_accuracy: 0.8904 - val_loss: 0.2890 - val_binary_accuracy: 0.8781 - lr: 0.0063\n",
      "Epoch 258/1000\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2491 - binary_accuracy: 0.8888 - val_loss: 0.2883 - val_binary_accuracy: 0.8762 - lr: 0.0063\n",
      "Epoch 259/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2474 - binary_accuracy: 0.8886 - val_loss: 0.2884 - val_binary_accuracy: 0.8746 - lr: 0.0063\n",
      "Epoch 260/1000\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2468 - binary_accuracy: 0.8890 - val_loss: 0.2859 - val_binary_accuracy: 0.8751 - lr: 0.0063\n",
      "Epoch 261/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2445 - binary_accuracy: 0.8910 - val_loss: 0.2870 - val_binary_accuracy: 0.8748 - lr: 0.0063\n",
      "Epoch 262/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2446 - binary_accuracy: 0.8899 - val_loss: 0.2866 - val_binary_accuracy: 0.8765 - lr: 0.0063\n",
      "Epoch 263/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2469 - binary_accuracy: 0.8885 - val_loss: 0.2866 - val_binary_accuracy: 0.8776 - lr: 0.0063\n",
      "Epoch 264/1000\n",
      "29/29 [==============================] - 13s 434ms/step - loss: 0.2450 - binary_accuracy: 0.8903 - val_loss: 0.2868 - val_binary_accuracy: 0.8787 - lr: 0.0063\n",
      "Epoch 265/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2432 - binary_accuracy: 0.8903 - val_loss: 0.2867 - val_binary_accuracy: 0.8757 - lr: 0.0063\n",
      "Epoch 266/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2439 - binary_accuracy: 0.8909 - val_loss: 0.2867 - val_binary_accuracy: 0.8773 - lr: 0.0063\n",
      "Epoch 267/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2453 - binary_accuracy: 0.8899 - val_loss: 0.2875 - val_binary_accuracy: 0.8779 - lr: 0.0063\n",
      "Epoch 268/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2451 - binary_accuracy: 0.8890 - val_loss: 0.2870 - val_binary_accuracy: 0.8770 - lr: 0.0063\n",
      "Epoch 269/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2444 - binary_accuracy: 0.8909 - val_loss: 0.2883 - val_binary_accuracy: 0.8762 - lr: 0.0063\n",
      "Epoch 270/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2438 - binary_accuracy: 0.8896 - val_loss: 0.2884 - val_binary_accuracy: 0.8770 - lr: 0.0063\n",
      "Epoch 271/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2455 - binary_accuracy: 0.8899 - val_loss: 0.2876 - val_binary_accuracy: 0.8779 - lr: 0.0031\n",
      "Epoch 272/1000\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2456 - binary_accuracy: 0.8881 - val_loss: 0.2873 - val_binary_accuracy: 0.8776 - lr: 0.0031\n",
      "Epoch 273/1000\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2441 - binary_accuracy: 0.8912 - val_loss: 0.2879 - val_binary_accuracy: 0.8773 - lr: 0.0031\n",
      "Epoch 274/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2454 - binary_accuracy: 0.8896 - val_loss: 0.2878 - val_binary_accuracy: 0.8773 - lr: 0.0031\n",
      "Epoch 275/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2444 - binary_accuracy: 0.8905 - val_loss: 0.2877 - val_binary_accuracy: 0.8773 - lr: 0.0031\n",
      "Epoch 276/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2418 - binary_accuracy: 0.8924 - val_loss: 0.2881 - val_binary_accuracy: 0.8773 - lr: 0.0031\n",
      "Epoch 277/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2419 - binary_accuracy: 0.8919 - val_loss: 0.2882 - val_binary_accuracy: 0.8779 - lr: 0.0031\n",
      "Epoch 278/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2451 - binary_accuracy: 0.8900 - val_loss: 0.2874 - val_binary_accuracy: 0.8770 - lr: 0.0031\n",
      "Epoch 279/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2419 - binary_accuracy: 0.8919 - val_loss: 0.2870 - val_binary_accuracy: 0.8776 - lr: 0.0031\n",
      "Epoch 280/1000\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2428 - binary_accuracy: 0.8904 - val_loss: 0.2875 - val_binary_accuracy: 0.8762 - lr: 0.0031\n",
      "Epoch 281/1000\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2441 - binary_accuracy: 0.8889 - val_loss: 0.2876 - val_binary_accuracy: 0.8770 - lr: 0.0031\n",
      "Epoch 282/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2425 - binary_accuracy: 0.8916 - val_loss: 0.2874 - val_binary_accuracy: 0.8759 - lr: 0.0031\n",
      "Epoch 283/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2439 - binary_accuracy: 0.8906 - val_loss: 0.2876 - val_binary_accuracy: 0.8773 - lr: 0.0031\n",
      "Epoch 284/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2447 - binary_accuracy: 0.8903 - val_loss: 0.2876 - val_binary_accuracy: 0.8754 - lr: 0.0031\n",
      "Epoch 285/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2420 - binary_accuracy: 0.8914 - val_loss: 0.2882 - val_binary_accuracy: 0.8754 - lr: 0.0031\n",
      "Epoch 286/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2439 - binary_accuracy: 0.8896 - val_loss: 0.2881 - val_binary_accuracy: 0.8748 - lr: 0.0031\n",
      "Epoch 287/1000\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2406 - binary_accuracy: 0.8921 - val_loss: 0.2879 - val_binary_accuracy: 0.8751 - lr: 0.0031\n",
      "Epoch 288/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2433 - binary_accuracy: 0.8912 - val_loss: 0.2874 - val_binary_accuracy: 0.8768 - lr: 0.0031\n",
      "Epoch 289/1000\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2420 - binary_accuracy: 0.8912 - val_loss: 0.2881 - val_binary_accuracy: 0.8765 - lr: 0.0031\n",
      "Epoch 290/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2421 - binary_accuracy: 0.8914 - val_loss: 0.2880 - val_binary_accuracy: 0.8762 - lr: 0.0031\n",
      "Epoch 291/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2422 - binary_accuracy: 0.8903 - val_loss: 0.2879 - val_binary_accuracy: 0.8762 - lr: 0.0016\n",
      "Epoch 292/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2456 - binary_accuracy: 0.8900 - val_loss: 0.2880 - val_binary_accuracy: 0.8757 - lr: 0.0016\n",
      "Epoch 293/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2406 - binary_accuracy: 0.8926 - val_loss: 0.2878 - val_binary_accuracy: 0.8762 - lr: 0.0016\n",
      "Epoch 294/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2412 - binary_accuracy: 0.8926 - val_loss: 0.2880 - val_binary_accuracy: 0.8762 - lr: 0.0016\n",
      "Epoch 295/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2407 - binary_accuracy: 0.8906 - val_loss: 0.2882 - val_binary_accuracy: 0.8757 - lr: 0.0016\n",
      "Epoch 296/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2418 - binary_accuracy: 0.8904 - val_loss: 0.2887 - val_binary_accuracy: 0.8757 - lr: 0.0016\n",
      "Epoch 297/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2418 - binary_accuracy: 0.8911 - val_loss: 0.2889 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 298/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2413 - binary_accuracy: 0.8919 - val_loss: 0.2889 - val_binary_accuracy: 0.8757 - lr: 0.0016\n",
      "Epoch 299/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2428 - binary_accuracy: 0.8918 - val_loss: 0.2888 - val_binary_accuracy: 0.8757 - lr: 0.0016\n",
      "Epoch 300/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2420 - binary_accuracy: 0.8909 - val_loss: 0.2886 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 301/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2419 - binary_accuracy: 0.8915 - val_loss: 0.2886 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 302/1000\n",
      "29/29 [==============================] - 13s 442ms/step - loss: 0.2417 - binary_accuracy: 0.8912 - val_loss: 0.2887 - val_binary_accuracy: 0.8759 - lr: 0.0016\n",
      "Epoch 303/1000\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.2398 - binary_accuracy: 0.8925 - val_loss: 0.2890 - val_binary_accuracy: 0.8770 - lr: 0.0016\n",
      "Epoch 304/1000\n",
      "29/29 [==============================] - 13s 436ms/step - loss: 0.2413 - binary_accuracy: 0.8917 - val_loss: 0.2887 - val_binary_accuracy: 0.8768 - lr: 0.0016\n",
      "Epoch 305/1000\n",
      "29/29 [==============================] - 13s 445ms/step - loss: 0.2411 - binary_accuracy: 0.8909 - val_loss: 0.2885 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 306/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2402 - binary_accuracy: 0.8912 - val_loss: 0.2887 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 307/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2414 - binary_accuracy: 0.8923 - val_loss: 0.2888 - val_binary_accuracy: 0.8770 - lr: 0.0016\n",
      "Epoch 308/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2414 - binary_accuracy: 0.8917 - val_loss: 0.2888 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 309/1000\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.2381 - binary_accuracy: 0.8931 - val_loss: 0.2891 - val_binary_accuracy: 0.8765 - lr: 0.0016\n",
      "Epoch 310/1000\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2400 - binary_accuracy: 0.8906 - val_loss: 0.2892 - val_binary_accuracy: 0.8781 - lr: 0.0016\n",
      "Epoch 311/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2422 - binary_accuracy: 0.8914 - val_loss: 0.2893 - val_binary_accuracy: 0.8781 - lr: 7.8125e-04\n",
      "Epoch 312/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2399 - binary_accuracy: 0.8910 - val_loss: 0.2891 - val_binary_accuracy: 0.8781 - lr: 7.8125e-04\n",
      "Epoch 313/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2406 - binary_accuracy: 0.8920 - val_loss: 0.2891 - val_binary_accuracy: 0.8779 - lr: 7.8125e-04\n",
      "Epoch 314/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2414 - binary_accuracy: 0.8908 - val_loss: 0.2891 - val_binary_accuracy: 0.8768 - lr: 7.8125e-04\n",
      "Epoch 315/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2399 - binary_accuracy: 0.8916 - val_loss: 0.2894 - val_binary_accuracy: 0.8770 - lr: 7.8125e-04\n",
      "Epoch 316/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2402 - binary_accuracy: 0.8907 - val_loss: 0.2894 - val_binary_accuracy: 0.8762 - lr: 7.8125e-04\n",
      "Epoch 317/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2411 - binary_accuracy: 0.8910 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 7.8125e-04\n",
      "Epoch 318/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2390 - binary_accuracy: 0.8927 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 7.8125e-04\n",
      "Epoch 319/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2411 - binary_accuracy: 0.8933 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 7.8125e-04\n",
      "Epoch 320/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2435 - binary_accuracy: 0.8901 - val_loss: 0.2896 - val_binary_accuracy: 0.8762 - lr: 7.8125e-04\n",
      "Epoch 321/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2400 - binary_accuracy: 0.8924 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 7.8125e-04\n",
      "Epoch 322/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2413 - binary_accuracy: 0.8923 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 7.8125e-04\n",
      "Epoch 323/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2436 - binary_accuracy: 0.8901 - val_loss: 0.2893 - val_binary_accuracy: 0.8770 - lr: 7.8125e-04\n",
      "Epoch 324/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2399 - binary_accuracy: 0.8922 - val_loss: 0.2892 - val_binary_accuracy: 0.8773 - lr: 7.8125e-04\n",
      "Epoch 325/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2408 - binary_accuracy: 0.8922 - val_loss: 0.2893 - val_binary_accuracy: 0.8776 - lr: 7.8125e-04\n",
      "Epoch 326/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2427 - binary_accuracy: 0.8902 - val_loss: 0.2894 - val_binary_accuracy: 0.8779 - lr: 7.8125e-04\n",
      "Epoch 327/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2402 - binary_accuracy: 0.8922 - val_loss: 0.2893 - val_binary_accuracy: 0.8770 - lr: 7.8125e-04\n",
      "Epoch 328/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2415 - binary_accuracy: 0.8906 - val_loss: 0.2892 - val_binary_accuracy: 0.8776 - lr: 7.8125e-04\n",
      "Epoch 329/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2401 - binary_accuracy: 0.8916 - val_loss: 0.2894 - val_binary_accuracy: 0.8776 - lr: 7.8125e-04\n",
      "Epoch 330/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2399 - binary_accuracy: 0.8917 - val_loss: 0.2893 - val_binary_accuracy: 0.8776 - lr: 7.8125e-04\n",
      "Epoch 331/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2391 - binary_accuracy: 0.8913 - val_loss: 0.2893 - val_binary_accuracy: 0.8779 - lr: 3.9063e-04\n",
      "Epoch 332/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2382 - binary_accuracy: 0.8932 - val_loss: 0.2893 - val_binary_accuracy: 0.8773 - lr: 3.9063e-04\n",
      "Epoch 333/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2422 - binary_accuracy: 0.8903 - val_loss: 0.2893 - val_binary_accuracy: 0.8776 - lr: 3.9063e-04\n",
      "Epoch 334/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2388 - binary_accuracy: 0.8924 - val_loss: 0.2895 - val_binary_accuracy: 0.8773 - lr: 3.9063e-04\n",
      "Epoch 335/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2409 - binary_accuracy: 0.8919 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 3.9063e-04\n",
      "Epoch 336/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2401 - binary_accuracy: 0.8924 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 3.9063e-04\n",
      "Epoch 337/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2394 - binary_accuracy: 0.8919 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 3.9063e-04\n",
      "Epoch 338/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2408 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 3.9063e-04\n",
      "Epoch 339/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2423 - binary_accuracy: 0.8900 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 3.9063e-04\n",
      "Epoch 340/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2407 - binary_accuracy: 0.8923 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 341/1000\n",
      "29/29 [==============================] - 13s 451ms/step - loss: 0.2426 - binary_accuracy: 0.8914 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 342/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2377 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 343/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2406 - binary_accuracy: 0.8911 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 344/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2408 - binary_accuracy: 0.8904 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 345/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2408 - binary_accuracy: 0.8914 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 3.9063e-04\n",
      "Epoch 346/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2395 - binary_accuracy: 0.8934 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 3.9063e-04\n",
      "Epoch 347/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2398 - binary_accuracy: 0.8926 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 3.9063e-04\n",
      "Epoch 348/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2387 - binary_accuracy: 0.8932 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 3.9063e-04\n",
      "Epoch 349/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2423 - binary_accuracy: 0.8900 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 350/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2396 - binary_accuracy: 0.8916 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 3.9063e-04\n",
      "Epoch 351/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2394 - binary_accuracy: 0.8917 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.9531e-04\n",
      "Epoch 352/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2377 - binary_accuracy: 0.8926 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.9531e-04\n",
      "Epoch 353/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2391 - binary_accuracy: 0.8918 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 354/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2391 - binary_accuracy: 0.8928 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 355/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2433 - binary_accuracy: 0.8908 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.9531e-04\n",
      "Epoch 356/1000\n",
      "29/29 [==============================] - 12s 433ms/step - loss: 0.2413 - binary_accuracy: 0.8922 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.9531e-04\n",
      "Epoch 357/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2403 - binary_accuracy: 0.8909 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 358/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2415 - binary_accuracy: 0.8923 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 359/1000\n",
      "29/29 [==============================] - 13s 435ms/step - loss: 0.2400 - binary_accuracy: 0.8928 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 360/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2408 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8762 - lr: 1.9531e-04\n",
      "Epoch 361/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2398 - binary_accuracy: 0.8922 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.9531e-04\n",
      "Epoch 362/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2423 - binary_accuracy: 0.8913 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.9531e-04\n",
      "Epoch 363/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2420 - binary_accuracy: 0.8899 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.9531e-04\n",
      "Epoch 364/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2406 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8776 - lr: 1.9531e-04\n",
      "Epoch 365/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2416 - binary_accuracy: 0.8909 - val_loss: 0.2897 - val_binary_accuracy: 0.8779 - lr: 1.9531e-04\n",
      "Epoch 366/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2411 - binary_accuracy: 0.8914 - val_loss: 0.2896 - val_binary_accuracy: 0.8776 - lr: 1.9531e-04\n",
      "Epoch 367/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2408 - binary_accuracy: 0.8923 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.9531e-04\n",
      "Epoch 368/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2415 - binary_accuracy: 0.8920 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.9531e-04\n",
      "Epoch 369/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2412 - binary_accuracy: 0.8916 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.9531e-04\n",
      "Epoch 370/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2420 - binary_accuracy: 0.8905 - val_loss: 0.2894 - val_binary_accuracy: 0.8762 - lr: 1.9531e-04\n",
      "Epoch 371/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2398 - binary_accuracy: 0.8941 - val_loss: 0.2894 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 372/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2390 - binary_accuracy: 0.8932 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 373/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2402 - binary_accuracy: 0.8921 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 374/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2380 - binary_accuracy: 0.8915 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 375/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2416 - binary_accuracy: 0.8909 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 376/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2401 - binary_accuracy: 0.8912 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 377/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2410 - binary_accuracy: 0.8924 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 378/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2404 - binary_accuracy: 0.8927 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 379/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2396 - binary_accuracy: 0.8929 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 380/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2379 - binary_accuracy: 0.8942 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 381/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2395 - binary_accuracy: 0.8931 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 382/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2406 - binary_accuracy: 0.8919 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 383/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2406 - binary_accuracy: 0.8925 - val_loss: 0.2895 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 384/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2403 - binary_accuracy: 0.8929 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 385/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2405 - binary_accuracy: 0.8920 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 386/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2420 - binary_accuracy: 0.8913 - val_loss: 0.2898 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 387/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2408 - binary_accuracy: 0.8909 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 388/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2402 - binary_accuracy: 0.8906 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 389/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2388 - binary_accuracy: 0.8919 - val_loss: 0.2896 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 390/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2403 - binary_accuracy: 0.8922 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 391/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2379 - binary_accuracy: 0.8924 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 392/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2395 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 393/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2415 - binary_accuracy: 0.8912 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 394/1000\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2412 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 395/1000\n",
      "29/29 [==============================] - 13s 434ms/step - loss: 0.2404 - binary_accuracy: 0.8922 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 396/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2427 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 397/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2412 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 398/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2402 - binary_accuracy: 0.8933 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 399/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2412 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 400/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2430 - binary_accuracy: 0.8903 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 401/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2404 - binary_accuracy: 0.8919 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 402/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2382 - binary_accuracy: 0.8924 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 403/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2410 - binary_accuracy: 0.8930 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 404/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2400 - binary_accuracy: 0.8932 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 405/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2403 - binary_accuracy: 0.8920 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 406/1000\n",
      "29/29 [==============================] - 13s 444ms/step - loss: 0.2418 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 407/1000\n",
      "29/29 [==============================] - 13s 443ms/step - loss: 0.2392 - binary_accuracy: 0.8922 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 408/1000\n",
      "29/29 [==============================] - 13s 456ms/step - loss: 0.2387 - binary_accuracy: 0.8928 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 409/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2415 - binary_accuracy: 0.8905 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 410/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2421 - binary_accuracy: 0.8909 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 411/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2419 - binary_accuracy: 0.8906 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 412/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2409 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 413/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2394 - binary_accuracy: 0.8914 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 414/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2397 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 415/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2391 - binary_accuracy: 0.8929 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 416/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2410 - binary_accuracy: 0.8926 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 417/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2381 - binary_accuracy: 0.8941 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 418/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2410 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 419/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2410 - binary_accuracy: 0.8925 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 420/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2404 - binary_accuracy: 0.8912 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 421/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2404 - binary_accuracy: 0.8910 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 422/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2410 - binary_accuracy: 0.8919 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 423/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2385 - binary_accuracy: 0.8939 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 424/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2427 - binary_accuracy: 0.8902 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 425/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2394 - binary_accuracy: 0.8934 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 426/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2396 - binary_accuracy: 0.8919 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 427/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2425 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 428/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2391 - binary_accuracy: 0.8917 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 429/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2408 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 430/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2410 - binary_accuracy: 0.8929 - val_loss: 0.2898 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 431/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2398 - binary_accuracy: 0.8912 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 432/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2403 - binary_accuracy: 0.8921 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 433/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2395 - binary_accuracy: 0.8914 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 434/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2411 - binary_accuracy: 0.8914 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 435/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2411 - binary_accuracy: 0.8931 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 436/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2396 - binary_accuracy: 0.8929 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 437/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2388 - binary_accuracy: 0.8930 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 438/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2399 - binary_accuracy: 0.8922 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 439/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2420 - binary_accuracy: 0.8904 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 440/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2421 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 441/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2403 - binary_accuracy: 0.8928 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 442/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2410 - binary_accuracy: 0.8917 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 443/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2376 - binary_accuracy: 0.8940 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 444/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2402 - binary_accuracy: 0.8911 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 445/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2376 - binary_accuracy: 0.8927 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 446/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2396 - binary_accuracy: 0.8909 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 447/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2404 - binary_accuracy: 0.8931 - val_loss: 0.2897 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 448/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2406 - binary_accuracy: 0.8921 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 449/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2407 - binary_accuracy: 0.8933 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 450/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2398 - binary_accuracy: 0.8932 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 451/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2406 - binary_accuracy: 0.8910 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 452/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2407 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 453/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2405 - binary_accuracy: 0.8938 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 454/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2411 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 455/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2413 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 456/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2393 - binary_accuracy: 0.8933 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 457/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2398 - binary_accuracy: 0.8923 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 458/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2414 - binary_accuracy: 0.8904 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 459/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2390 - binary_accuracy: 0.8932 - val_loss: 0.2898 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 460/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2403 - binary_accuracy: 0.8899 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 461/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2394 - binary_accuracy: 0.8913 - val_loss: 0.2899 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 462/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2417 - binary_accuracy: 0.8903 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 463/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2392 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 464/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2407 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 465/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2384 - binary_accuracy: 0.8926 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 466/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2392 - binary_accuracy: 0.8939 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 467/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2410 - binary_accuracy: 0.8922 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 468/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2402 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 469/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2410 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 470/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2414 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 471/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2401 - binary_accuracy: 0.8907 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 472/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2413 - binary_accuracy: 0.8915 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 473/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2390 - binary_accuracy: 0.8925 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 474/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2418 - binary_accuracy: 0.8902 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 475/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2410 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 476/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2393 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 477/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2401 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 478/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2413 - binary_accuracy: 0.8912 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 479/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2398 - binary_accuracy: 0.8920 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 480/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2403 - binary_accuracy: 0.8916 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 481/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2434 - binary_accuracy: 0.8914 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 482/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2410 - binary_accuracy: 0.8923 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 483/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2402 - binary_accuracy: 0.8921 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 484/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2405 - binary_accuracy: 0.8906 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 485/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2394 - binary_accuracy: 0.8926 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 486/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2407 - binary_accuracy: 0.8919 - val_loss: 0.2894 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 487/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2396 - binary_accuracy: 0.8913 - val_loss: 0.2894 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 488/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2398 - binary_accuracy: 0.8949 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 489/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2394 - binary_accuracy: 0.8928 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 490/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2406 - binary_accuracy: 0.8912 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 491/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2407 - binary_accuracy: 0.8921 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 492/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2406 - binary_accuracy: 0.8920 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 493/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2421 - binary_accuracy: 0.8930 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 494/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2390 - binary_accuracy: 0.8924 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 495/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2408 - binary_accuracy: 0.8925 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 496/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2387 - binary_accuracy: 0.8932 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 497/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2399 - binary_accuracy: 0.8926 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 498/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2406 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 499/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2389 - binary_accuracy: 0.8929 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 500/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2398 - binary_accuracy: 0.8906 - val_loss: 0.2895 - val_binary_accuracy: 0.8759 - lr: 1.0000e-04\n",
      "Epoch 501/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2406 - binary_accuracy: 0.8927 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 502/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2399 - binary_accuracy: 0.8918 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 503/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2413 - binary_accuracy: 0.8910 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 504/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2406 - binary_accuracy: 0.8924 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 505/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2397 - binary_accuracy: 0.8918 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 506/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2385 - binary_accuracy: 0.8925 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 507/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2406 - binary_accuracy: 0.8903 - val_loss: 0.2896 - val_binary_accuracy: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 508/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2393 - binary_accuracy: 0.8926 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 509/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2412 - binary_accuracy: 0.8915 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 510/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2394 - binary_accuracy: 0.8932 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 511/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2394 - binary_accuracy: 0.8922 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 512/1000\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2391 - binary_accuracy: 0.8915 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 513/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2415 - binary_accuracy: 0.8923 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 514/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2422 - binary_accuracy: 0.8900 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 515/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2422 - binary_accuracy: 0.8910 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 516/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2427 - binary_accuracy: 0.8906 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 517/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2400 - binary_accuracy: 0.8923 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 518/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2405 - binary_accuracy: 0.8921 - val_loss: 0.2894 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 519/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2409 - binary_accuracy: 0.8926 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 520/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2380 - binary_accuracy: 0.8928 - val_loss: 0.2895 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 521/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2407 - binary_accuracy: 0.8925 - val_loss: 0.2894 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 522/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2380 - binary_accuracy: 0.8929 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 523/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2382 - binary_accuracy: 0.8916 - val_loss: 0.2895 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 524/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2413 - binary_accuracy: 0.8916 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 525/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2378 - binary_accuracy: 0.8933 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 526/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2391 - binary_accuracy: 0.8928 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 527/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2393 - binary_accuracy: 0.8927 - val_loss: 0.2896 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 528/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2395 - binary_accuracy: 0.8939 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 529/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2406 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 530/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2414 - binary_accuracy: 0.8924 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 531/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2405 - binary_accuracy: 0.8927 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 532/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2405 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 533/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2409 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 534/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2375 - binary_accuracy: 0.8940 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 535/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2422 - binary_accuracy: 0.8912 - val_loss: 0.2895 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 536/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2406 - binary_accuracy: 0.8937 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 537/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2390 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 538/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2411 - binary_accuracy: 0.8911 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 539/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2382 - binary_accuracy: 0.8939 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 540/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2407 - binary_accuracy: 0.8909 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 541/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2382 - binary_accuracy: 0.8929 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 542/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2422 - binary_accuracy: 0.8925 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 543/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2432 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 544/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2404 - binary_accuracy: 0.8931 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 545/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2395 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 546/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2395 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 547/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2393 - binary_accuracy: 0.8927 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 548/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2399 - binary_accuracy: 0.8915 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 549/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2415 - binary_accuracy: 0.8911 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 550/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2401 - binary_accuracy: 0.8925 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 551/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2425 - binary_accuracy: 0.8890 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 552/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2385 - binary_accuracy: 0.8924 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 553/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2396 - binary_accuracy: 0.8922 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 554/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2394 - binary_accuracy: 0.8929 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 555/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2399 - binary_accuracy: 0.8910 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 556/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2407 - binary_accuracy: 0.8907 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 557/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2387 - binary_accuracy: 0.8925 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 558/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2396 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 559/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2401 - binary_accuracy: 0.8926 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 560/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2395 - binary_accuracy: 0.8916 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 561/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2403 - binary_accuracy: 0.8918 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 562/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2410 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 563/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2385 - binary_accuracy: 0.8928 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 564/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2390 - binary_accuracy: 0.8929 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 565/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2406 - binary_accuracy: 0.8931 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 566/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2408 - binary_accuracy: 0.8913 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 567/1000\n",
      "29/29 [==============================] - 13s 445ms/step - loss: 0.2391 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 568/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2393 - binary_accuracy: 0.8919 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 569/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2420 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 570/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2422 - binary_accuracy: 0.8907 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 571/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2383 - binary_accuracy: 0.8932 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 572/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2385 - binary_accuracy: 0.8922 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 573/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2410 - binary_accuracy: 0.8916 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 574/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2430 - binary_accuracy: 0.8905 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 575/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2386 - binary_accuracy: 0.8934 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 576/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2414 - binary_accuracy: 0.8932 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 577/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2407 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 578/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2395 - binary_accuracy: 0.8913 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 579/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2383 - binary_accuracy: 0.8916 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 580/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2411 - binary_accuracy: 0.8908 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 581/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2388 - binary_accuracy: 0.8930 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 582/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2403 - binary_accuracy: 0.8930 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 583/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2422 - binary_accuracy: 0.8914 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 584/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2390 - binary_accuracy: 0.8934 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 585/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2395 - binary_accuracy: 0.8917 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 586/1000\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2403 - binary_accuracy: 0.8922 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 587/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2392 - binary_accuracy: 0.8925 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 588/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2400 - binary_accuracy: 0.8900 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 589/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2392 - binary_accuracy: 0.8919 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 590/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2391 - binary_accuracy: 0.8917 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 591/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2404 - binary_accuracy: 0.8923 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 592/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2423 - binary_accuracy: 0.8916 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 593/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2408 - binary_accuracy: 0.8903 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 594/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2395 - binary_accuracy: 0.8919 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 595/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2396 - binary_accuracy: 0.8930 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 596/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2409 - binary_accuracy: 0.8925 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 597/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2405 - binary_accuracy: 0.8921 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 598/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2403 - binary_accuracy: 0.8931 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 599/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2393 - binary_accuracy: 0.8913 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 600/1000\n",
      "29/29 [==============================] - 14s 501ms/step - loss: 0.2377 - binary_accuracy: 0.8922 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 601/1000\n",
      "29/29 [==============================] - 15s 503ms/step - loss: 0.2426 - binary_accuracy: 0.8890 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 602/1000\n",
      "29/29 [==============================] - 14s 475ms/step - loss: 0.2422 - binary_accuracy: 0.8907 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 603/1000\n",
      "29/29 [==============================] - 13s 466ms/step - loss: 0.2406 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 604/1000\n",
      "29/29 [==============================] - 14s 468ms/step - loss: 0.2393 - binary_accuracy: 0.8923 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 605/1000\n",
      "29/29 [==============================] - 13s 464ms/step - loss: 0.2395 - binary_accuracy: 0.8912 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 606/1000\n",
      "29/29 [==============================] - 14s 468ms/step - loss: 0.2393 - binary_accuracy: 0.8922 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 607/1000\n",
      "29/29 [==============================] - 13s 465ms/step - loss: 0.2400 - binary_accuracy: 0.8934 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 608/1000\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 0.2399 - binary_accuracy: 0.8922 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 609/1000\n",
      "29/29 [==============================] - 14s 466ms/step - loss: 0.2413 - binary_accuracy: 0.8916 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 610/1000\n",
      "29/29 [==============================] - 14s 475ms/step - loss: 0.2404 - binary_accuracy: 0.8916 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 611/1000\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 0.2392 - binary_accuracy: 0.8920 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 612/1000\n",
      "29/29 [==============================] - 14s 469ms/step - loss: 0.2420 - binary_accuracy: 0.8916 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 613/1000\n",
      "29/29 [==============================] - 14s 483ms/step - loss: 0.2407 - binary_accuracy: 0.8924 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 614/1000\n",
      "29/29 [==============================] - 14s 469ms/step - loss: 0.2391 - binary_accuracy: 0.8930 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 615/1000\n",
      "29/29 [==============================] - 14s 466ms/step - loss: 0.2408 - binary_accuracy: 0.8926 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 616/1000\n",
      "29/29 [==============================] - 16s 567ms/step - loss: 0.2422 - binary_accuracy: 0.8891 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 617/1000\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 0.2379 - binary_accuracy: 0.8929 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 618/1000\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2399 - binary_accuracy: 0.8915 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 619/1000\n",
      "29/29 [==============================] - 14s 474ms/step - loss: 0.2388 - binary_accuracy: 0.8916 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 620/1000\n",
      "29/29 [==============================] - 14s 477ms/step - loss: 0.2389 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 621/1000\n",
      "29/29 [==============================] - 14s 466ms/step - loss: 0.2417 - binary_accuracy: 0.8911 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 622/1000\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 0.2404 - binary_accuracy: 0.8913 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 623/1000\n",
      "29/29 [==============================] - 13s 465ms/step - loss: 0.2397 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 624/1000\n",
      "29/29 [==============================] - 13s 463ms/step - loss: 0.2399 - binary_accuracy: 0.8913 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 625/1000\n",
      "29/29 [==============================] - 15s 513ms/step - loss: 0.2393 - binary_accuracy: 0.8914 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 626/1000\n",
      "29/29 [==============================] - 16s 555ms/step - loss: 0.2406 - binary_accuracy: 0.8935 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 627/1000\n",
      "29/29 [==============================] - 14s 494ms/step - loss: 0.2399 - binary_accuracy: 0.8925 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 628/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.2417 - binary_accuracy: 0.8910 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 629/1000\n",
      "29/29 [==============================] - 14s 479ms/step - loss: 0.2379 - binary_accuracy: 0.8935 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 630/1000\n",
      "29/29 [==============================] - 14s 481ms/step - loss: 0.2385 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 631/1000\n",
      "29/29 [==============================] - 16s 556ms/step - loss: 0.2390 - binary_accuracy: 0.8930 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 632/1000\n",
      "29/29 [==============================] - 15s 527ms/step - loss: 0.2410 - binary_accuracy: 0.8919 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 633/1000\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2385 - binary_accuracy: 0.8932 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 634/1000\n",
      "29/29 [==============================] - 14s 495ms/step - loss: 0.2398 - binary_accuracy: 0.8915 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 635/1000\n",
      "29/29 [==============================] - 13s 440ms/step - loss: 0.2411 - binary_accuracy: 0.8913 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 636/1000\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2389 - binary_accuracy: 0.8920 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 637/1000\n",
      "29/29 [==============================] - 13s 460ms/step - loss: 0.2406 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 638/1000\n",
      "29/29 [==============================] - 14s 482ms/step - loss: 0.2388 - binary_accuracy: 0.8907 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 639/1000\n",
      "29/29 [==============================] - 14s 492ms/step - loss: 0.2392 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 640/1000\n",
      "29/29 [==============================] - 14s 469ms/step - loss: 0.2410 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 641/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.2404 - binary_accuracy: 0.8917 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 642/1000\n",
      "29/29 [==============================] - 13s 444ms/step - loss: 0.2406 - binary_accuracy: 0.8916 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 643/1000\n",
      "29/29 [==============================] - 13s 457ms/step - loss: 0.2393 - binary_accuracy: 0.8930 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 644/1000\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2391 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 645/1000\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2404 - binary_accuracy: 0.8912 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 646/1000\n",
      "29/29 [==============================] - 14s 491ms/step - loss: 0.2398 - binary_accuracy: 0.8920 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 647/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2415 - binary_accuracy: 0.8909 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 648/1000\n",
      "29/29 [==============================] - 13s 439ms/step - loss: 0.2395 - binary_accuracy: 0.8927 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 649/1000\n",
      "29/29 [==============================] - 14s 492ms/step - loss: 0.2400 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 650/1000\n",
      "29/29 [==============================] - 14s 494ms/step - loss: 0.2419 - binary_accuracy: 0.8916 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 651/1000\n",
      "29/29 [==============================] - 14s 495ms/step - loss: 0.2409 - binary_accuracy: 0.8918 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 652/1000\n",
      "29/29 [==============================] - 14s 489ms/step - loss: 0.2397 - binary_accuracy: 0.8921 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 653/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.2413 - binary_accuracy: 0.8927 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 654/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2394 - binary_accuracy: 0.8925 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 655/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2399 - binary_accuracy: 0.8925 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 656/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2413 - binary_accuracy: 0.8912 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 657/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2382 - binary_accuracy: 0.8932 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 658/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2407 - binary_accuracy: 0.8912 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 659/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2399 - binary_accuracy: 0.8935 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 660/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2417 - binary_accuracy: 0.8909 - val_loss: 0.2896 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 661/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2368 - binary_accuracy: 0.8935 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 662/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2422 - binary_accuracy: 0.8900 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 663/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2389 - binary_accuracy: 0.8918 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 664/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2415 - binary_accuracy: 0.8912 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 665/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2404 - binary_accuracy: 0.8923 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 666/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2407 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 667/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2406 - binary_accuracy: 0.8914 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 668/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2408 - binary_accuracy: 0.8921 - val_loss: 0.2896 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 669/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2417 - binary_accuracy: 0.8901 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 670/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2400 - binary_accuracy: 0.8936 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 671/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2399 - binary_accuracy: 0.8920 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 672/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2395 - binary_accuracy: 0.8919 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 673/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2399 - binary_accuracy: 0.8934 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 674/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2418 - binary_accuracy: 0.8901 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 675/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2382 - binary_accuracy: 0.8932 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 676/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2407 - binary_accuracy: 0.8916 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 677/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2388 - binary_accuracy: 0.8935 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 678/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2384 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 679/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2401 - binary_accuracy: 0.8936 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 680/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2397 - binary_accuracy: 0.8922 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 681/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2400 - binary_accuracy: 0.8912 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 682/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2398 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 683/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2397 - binary_accuracy: 0.8924 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 684/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2394 - binary_accuracy: 0.8911 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 685/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2376 - binary_accuracy: 0.8937 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 686/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2376 - binary_accuracy: 0.8933 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 687/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2408 - binary_accuracy: 0.8915 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 688/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2399 - binary_accuracy: 0.8934 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 689/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2427 - binary_accuracy: 0.8906 - val_loss: 0.2901 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 690/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2401 - binary_accuracy: 0.8926 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 691/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2383 - binary_accuracy: 0.8932 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 692/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2415 - binary_accuracy: 0.8910 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 693/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2399 - binary_accuracy: 0.8902 - val_loss: 0.2899 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 694/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2415 - binary_accuracy: 0.8919 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 695/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2406 - binary_accuracy: 0.8924 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 696/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2400 - binary_accuracy: 0.8927 - val_loss: 0.2896 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 697/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2391 - binary_accuracy: 0.8932 - val_loss: 0.2897 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 698/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2377 - binary_accuracy: 0.8923 - val_loss: 0.2897 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 699/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2400 - binary_accuracy: 0.8911 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 700/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2408 - binary_accuracy: 0.8929 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 701/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2390 - binary_accuracy: 0.8936 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 702/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2404 - binary_accuracy: 0.8935 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 703/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2390 - binary_accuracy: 0.8927 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 704/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2412 - binary_accuracy: 0.8916 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 705/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2404 - binary_accuracy: 0.8931 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 706/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2381 - binary_accuracy: 0.8936 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 707/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2387 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 708/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2379 - binary_accuracy: 0.8928 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 709/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2410 - binary_accuracy: 0.8925 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 710/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2382 - binary_accuracy: 0.8924 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 711/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2382 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 712/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2398 - binary_accuracy: 0.8937 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 713/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2405 - binary_accuracy: 0.8925 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 714/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2382 - binary_accuracy: 0.8937 - val_loss: 0.2898 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 715/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2402 - binary_accuracy: 0.8922 - val_loss: 0.2897 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 716/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2371 - binary_accuracy: 0.8940 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 717/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2403 - binary_accuracy: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 718/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2392 - binary_accuracy: 0.8931 - val_loss: 0.2898 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 719/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2404 - binary_accuracy: 0.8914 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 720/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2404 - binary_accuracy: 0.8921 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 721/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2405 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 722/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2405 - binary_accuracy: 0.8927 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 723/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2386 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 724/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2396 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 725/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2394 - binary_accuracy: 0.8915 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 726/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2438 - binary_accuracy: 0.8913 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 727/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2380 - binary_accuracy: 0.8940 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 728/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2394 - binary_accuracy: 0.8934 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 729/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2393 - binary_accuracy: 0.8920 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 730/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2404 - binary_accuracy: 0.8917 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 731/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2391 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 732/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2369 - binary_accuracy: 0.8934 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 733/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2398 - binary_accuracy: 0.8925 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 734/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2369 - binary_accuracy: 0.8930 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 735/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2416 - binary_accuracy: 0.8911 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 736/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2392 - binary_accuracy: 0.8919 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 737/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2396 - binary_accuracy: 0.8928 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 738/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2412 - binary_accuracy: 0.8926 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 739/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2385 - binary_accuracy: 0.8921 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 740/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2383 - binary_accuracy: 0.8936 - val_loss: 0.2899 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 741/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2400 - binary_accuracy: 0.8921 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 742/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2409 - binary_accuracy: 0.8913 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 743/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2391 - binary_accuracy: 0.8933 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 744/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2395 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 745/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2378 - binary_accuracy: 0.8916 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 746/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2395 - binary_accuracy: 0.8926 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 747/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2396 - binary_accuracy: 0.8925 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 748/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2410 - binary_accuracy: 0.8909 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 749/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2384 - binary_accuracy: 0.8942 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 750/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2391 - binary_accuracy: 0.8931 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 751/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2390 - binary_accuracy: 0.8923 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 752/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2393 - binary_accuracy: 0.8917 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 753/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2397 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 754/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2383 - binary_accuracy: 0.8925 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 755/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2401 - binary_accuracy: 0.8909 - val_loss: 0.2898 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 756/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2415 - binary_accuracy: 0.8923 - val_loss: 0.2899 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 757/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2401 - binary_accuracy: 0.8920 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 758/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2387 - binary_accuracy: 0.8921 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 759/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2365 - binary_accuracy: 0.8935 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 760/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2408 - binary_accuracy: 0.8929 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 761/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2384 - binary_accuracy: 0.8932 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 762/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2388 - binary_accuracy: 0.8929 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 763/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2388 - binary_accuracy: 0.8919 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 764/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2391 - binary_accuracy: 0.8929 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 765/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2386 - binary_accuracy: 0.8924 - val_loss: 0.2898 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 766/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2394 - binary_accuracy: 0.8918 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 767/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2404 - binary_accuracy: 0.8907 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 768/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2408 - binary_accuracy: 0.8907 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 769/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2394 - binary_accuracy: 0.8926 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 770/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2382 - binary_accuracy: 0.8929 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 771/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2375 - binary_accuracy: 0.8926 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 772/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2410 - binary_accuracy: 0.8913 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 773/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2412 - binary_accuracy: 0.8905 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 774/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2394 - binary_accuracy: 0.8910 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 775/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2372 - binary_accuracy: 0.8946 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 776/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2396 - binary_accuracy: 0.8920 - val_loss: 0.2902 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 777/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2392 - binary_accuracy: 0.8921 - val_loss: 0.2903 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 778/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2412 - binary_accuracy: 0.8919 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 779/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2391 - binary_accuracy: 0.8924 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 780/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2414 - binary_accuracy: 0.8913 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 781/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2399 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 782/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2393 - binary_accuracy: 0.8917 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 783/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2372 - binary_accuracy: 0.8938 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 784/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2385 - binary_accuracy: 0.8937 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 785/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2381 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 786/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2388 - binary_accuracy: 0.8933 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 787/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2382 - binary_accuracy: 0.8932 - val_loss: 0.2901 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 788/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2384 - binary_accuracy: 0.8943 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 789/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2419 - binary_accuracy: 0.8908 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 790/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2386 - binary_accuracy: 0.8923 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 791/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2406 - binary_accuracy: 0.8911 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 792/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2418 - binary_accuracy: 0.8923 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 793/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2416 - binary_accuracy: 0.8912 - val_loss: 0.2903 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 794/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2367 - binary_accuracy: 0.8929 - val_loss: 0.2903 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 795/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2381 - binary_accuracy: 0.8937 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 796/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2400 - binary_accuracy: 0.8907 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 797/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2381 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 798/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2414 - binary_accuracy: 0.8913 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 799/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2400 - binary_accuracy: 0.8917 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 800/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2400 - binary_accuracy: 0.8916 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 801/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2396 - binary_accuracy: 0.8919 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 802/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2402 - binary_accuracy: 0.8935 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 803/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2396 - binary_accuracy: 0.8923 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 804/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2398 - binary_accuracy: 0.8925 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 805/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2405 - binary_accuracy: 0.8923 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 806/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2386 - binary_accuracy: 0.8926 - val_loss: 0.2901 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 807/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2393 - binary_accuracy: 0.8914 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 808/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2412 - binary_accuracy: 0.8920 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 809/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2407 - binary_accuracy: 0.8934 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 810/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2388 - binary_accuracy: 0.8926 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 811/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2366 - binary_accuracy: 0.8922 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 812/1000\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2364 - binary_accuracy: 0.8947 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 813/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2386 - binary_accuracy: 0.8908 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 814/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2394 - binary_accuracy: 0.8925 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 815/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2380 - binary_accuracy: 0.8927 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 816/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2386 - binary_accuracy: 0.8924 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 817/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2380 - binary_accuracy: 0.8915 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 818/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2377 - binary_accuracy: 0.8925 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 819/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2406 - binary_accuracy: 0.8923 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 820/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2390 - binary_accuracy: 0.8935 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 821/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2395 - binary_accuracy: 0.8916 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 822/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2393 - binary_accuracy: 0.8931 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 823/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2363 - binary_accuracy: 0.8927 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 824/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2395 - binary_accuracy: 0.8927 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 825/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2389 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 826/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2374 - binary_accuracy: 0.8940 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 827/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2410 - binary_accuracy: 0.8909 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 828/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2399 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 829/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2395 - binary_accuracy: 0.8911 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 830/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2397 - binary_accuracy: 0.8922 - val_loss: 0.2903 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 831/1000\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2380 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 832/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2416 - binary_accuracy: 0.8914 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 833/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2388 - binary_accuracy: 0.8933 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 834/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2367 - binary_accuracy: 0.8933 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 835/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2379 - binary_accuracy: 0.8930 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 836/1000\n",
      "29/29 [==============================] - 13s 463ms/step - loss: 0.2378 - binary_accuracy: 0.8936 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 837/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2399 - binary_accuracy: 0.8910 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 838/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2390 - binary_accuracy: 0.8920 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 839/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2372 - binary_accuracy: 0.8941 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 840/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2400 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 841/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2403 - binary_accuracy: 0.8925 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 842/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2418 - binary_accuracy: 0.8903 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 843/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2403 - binary_accuracy: 0.8911 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 844/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2415 - binary_accuracy: 0.8915 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 845/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2351 - binary_accuracy: 0.8942 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 846/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2395 - binary_accuracy: 0.8940 - val_loss: 0.2902 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 847/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2403 - binary_accuracy: 0.8915 - val_loss: 0.2902 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 848/1000\n",
      "29/29 [==============================] - 14s 482ms/step - loss: 0.2384 - binary_accuracy: 0.8932 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 849/1000\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.2403 - binary_accuracy: 0.8934 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 850/1000\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 0.2382 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 851/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.2376 - binary_accuracy: 0.8934 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 852/1000\n",
      "29/29 [==============================] - 13s 440ms/step - loss: 0.2389 - binary_accuracy: 0.8917 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 853/1000\n",
      "29/29 [==============================] - 13s 447ms/step - loss: 0.2396 - binary_accuracy: 0.8923 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 854/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2388 - binary_accuracy: 0.8919 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 855/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2387 - binary_accuracy: 0.8927 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 856/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.2391 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 857/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2388 - binary_accuracy: 0.8915 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 858/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2401 - binary_accuracy: 0.8924 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 859/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2388 - binary_accuracy: 0.8937 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 860/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2382 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 861/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2414 - binary_accuracy: 0.8920 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 862/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2412 - binary_accuracy: 0.8927 - val_loss: 0.2904 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 863/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2395 - binary_accuracy: 0.8915 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 864/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2377 - binary_accuracy: 0.8926 - val_loss: 0.2904 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 865/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2419 - binary_accuracy: 0.8912 - val_loss: 0.2904 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 866/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2388 - binary_accuracy: 0.8931 - val_loss: 0.2905 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 867/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2389 - binary_accuracy: 0.8917 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 868/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2399 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 869/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2410 - binary_accuracy: 0.8917 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 870/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2398 - binary_accuracy: 0.8913 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 871/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2403 - binary_accuracy: 0.8920 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 872/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2387 - binary_accuracy: 0.8931 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 873/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2407 - binary_accuracy: 0.8909 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 874/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2393 - binary_accuracy: 0.8916 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 875/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2387 - binary_accuracy: 0.8924 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 876/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2407 - binary_accuracy: 0.8931 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 877/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2381 - binary_accuracy: 0.8929 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 878/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2405 - binary_accuracy: 0.8912 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 879/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2385 - binary_accuracy: 0.8935 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 880/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2423 - binary_accuracy: 0.8927 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 881/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2423 - binary_accuracy: 0.8907 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 882/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2367 - binary_accuracy: 0.8947 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 883/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2395 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 884/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2409 - binary_accuracy: 0.8921 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 885/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2400 - binary_accuracy: 0.8908 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 886/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2408 - binary_accuracy: 0.8901 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 887/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2409 - binary_accuracy: 0.8925 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 888/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2391 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 889/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2384 - binary_accuracy: 0.8934 - val_loss: 0.2902 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 890/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2409 - binary_accuracy: 0.8906 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 891/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2389 - binary_accuracy: 0.8931 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 892/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2372 - binary_accuracy: 0.8925 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 893/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2380 - binary_accuracy: 0.8916 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 894/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2366 - binary_accuracy: 0.8931 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 895/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2414 - binary_accuracy: 0.8910 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 896/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2373 - binary_accuracy: 0.8918 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 897/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2392 - binary_accuracy: 0.8927 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 898/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2392 - binary_accuracy: 0.8917 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 899/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2403 - binary_accuracy: 0.8919 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 900/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.2383 - binary_accuracy: 0.8931 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 901/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2408 - binary_accuracy: 0.8935 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 902/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2418 - binary_accuracy: 0.8916 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 903/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2407 - binary_accuracy: 0.8915 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 904/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2389 - binary_accuracy: 0.8912 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 905/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2403 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 906/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2376 - binary_accuracy: 0.8920 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 907/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2396 - binary_accuracy: 0.8921 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 908/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2384 - binary_accuracy: 0.8921 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 909/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2388 - binary_accuracy: 0.8929 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 910/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2368 - binary_accuracy: 0.8937 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 911/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2378 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 912/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2391 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 913/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2382 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 914/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2370 - binary_accuracy: 0.8935 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 915/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2380 - binary_accuracy: 0.8925 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 916/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2399 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 917/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2382 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 918/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2401 - binary_accuracy: 0.8915 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 919/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2375 - binary_accuracy: 0.8932 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 920/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2395 - binary_accuracy: 0.8925 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 921/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2394 - binary_accuracy: 0.8919 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 922/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2384 - binary_accuracy: 0.8939 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 923/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2421 - binary_accuracy: 0.8913 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 924/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2372 - binary_accuracy: 0.8915 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 925/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2381 - binary_accuracy: 0.8937 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 926/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2384 - binary_accuracy: 0.8924 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 927/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2368 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 928/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2401 - binary_accuracy: 0.8934 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 929/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2414 - binary_accuracy: 0.8900 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 930/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2382 - binary_accuracy: 0.8918 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 931/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2395 - binary_accuracy: 0.8925 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 932/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2413 - binary_accuracy: 0.8913 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 933/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2418 - binary_accuracy: 0.8912 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 934/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2388 - binary_accuracy: 0.8916 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 935/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2389 - binary_accuracy: 0.8920 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 936/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2409 - binary_accuracy: 0.8927 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 937/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2389 - binary_accuracy: 0.8939 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 938/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2404 - binary_accuracy: 0.8931 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 939/1000\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2404 - binary_accuracy: 0.8930 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 940/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2377 - binary_accuracy: 0.8936 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 941/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2384 - binary_accuracy: 0.8924 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 942/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2405 - binary_accuracy: 0.8909 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 943/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2391 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 944/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2404 - binary_accuracy: 0.8925 - val_loss: 0.2902 - val_binary_accuracy: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 945/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2389 - binary_accuracy: 0.8927 - val_loss: 0.2901 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 946/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2394 - binary_accuracy: 0.8911 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 947/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2372 - binary_accuracy: 0.8932 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 948/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2395 - binary_accuracy: 0.8928 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 949/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2400 - binary_accuracy: 0.8918 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 950/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2378 - binary_accuracy: 0.8921 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 951/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2367 - binary_accuracy: 0.8929 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 952/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2401 - binary_accuracy: 0.8915 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 953/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2391 - binary_accuracy: 0.8920 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 954/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2384 - binary_accuracy: 0.8923 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 955/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2385 - binary_accuracy: 0.8920 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 956/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2405 - binary_accuracy: 0.8921 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 957/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2352 - binary_accuracy: 0.8947 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 958/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2387 - binary_accuracy: 0.8936 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 959/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2429 - binary_accuracy: 0.8910 - val_loss: 0.2899 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 960/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2404 - binary_accuracy: 0.8906 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 961/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2417 - binary_accuracy: 0.8915 - val_loss: 0.2899 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 962/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2389 - binary_accuracy: 0.8919 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 963/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2406 - binary_accuracy: 0.8924 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 964/1000\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 0.2392 - binary_accuracy: 0.8920 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 965/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2403 - binary_accuracy: 0.8918 - val_loss: 0.2902 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 966/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2392 - binary_accuracy: 0.8923 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 967/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2363 - binary_accuracy: 0.8951 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 968/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2394 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 969/1000\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2385 - binary_accuracy: 0.8920 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 970/1000\n",
      "29/29 [==============================] - 12s 432ms/step - loss: 0.2394 - binary_accuracy: 0.8915 - val_loss: 0.2900 - val_binary_accuracy: 0.8768 - lr: 1.0000e-04\n",
      "Epoch 971/1000\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 0.2374 - binary_accuracy: 0.8935 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 972/1000\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2404 - binary_accuracy: 0.8908 - val_loss: 0.2900 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 973/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.2409 - binary_accuracy: 0.8915 - val_loss: 0.2901 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 974/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2401 - binary_accuracy: 0.8926 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 975/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2380 - binary_accuracy: 0.8940 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 976/1000\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2405 - binary_accuracy: 0.8922 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 977/1000\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2425 - binary_accuracy: 0.8906 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 978/1000\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2375 - binary_accuracy: 0.8925 - val_loss: 0.2903 - val_binary_accuracy: 0.8770 - lr: 1.0000e-04\n",
      "Epoch 979/1000\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2386 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 980/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2395 - binary_accuracy: 0.8922 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 981/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.2378 - binary_accuracy: 0.8940 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 982/1000\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 0.2401 - binary_accuracy: 0.8915 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 983/1000\n",
      "29/29 [==============================] - 12s 403ms/step - loss: 0.2401 - binary_accuracy: 0.8936 - val_loss: 0.2905 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 984/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2395 - binary_accuracy: 0.8918 - val_loss: 0.2904 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 985/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2402 - binary_accuracy: 0.8918 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 986/1000\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 0.2386 - binary_accuracy: 0.8919 - val_loss: 0.2902 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 987/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2387 - binary_accuracy: 0.8909 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 988/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2377 - binary_accuracy: 0.8922 - val_loss: 0.2903 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 989/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.2409 - binary_accuracy: 0.8915 - val_loss: 0.2902 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 990/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.2420 - binary_accuracy: 0.8919 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 991/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.2389 - binary_accuracy: 0.8917 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 992/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2384 - binary_accuracy: 0.8933 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 993/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2396 - binary_accuracy: 0.8919 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 994/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2395 - binary_accuracy: 0.8924 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 995/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2393 - binary_accuracy: 0.8921 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 996/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2394 - binary_accuracy: 0.8930 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 997/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.2396 - binary_accuracy: 0.8926 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 998/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.2402 - binary_accuracy: 0.8913 - val_loss: 0.2900 - val_binary_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 999/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.2361 - binary_accuracy: 0.8942 - val_loss: 0.2901 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 1000/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.2382 - binary_accuracy: 0.8927 - val_loss: 0.2900 - val_binary_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "11956.7852859\n"
     ]
    }
   ],
   "source": [
    "#Entrenar el modelo\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(X_val, y_val), callbacks=[reduce_lr])\n",
    "print (time.perf_counter() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtener los resultados\n",
    "title = f\"Training History - Optimizer: {type(opt).__name__}, Learning Rate: {opt.get_config()['learning_rate']}\"\n",
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5), title=title)\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.savefig(f\"./images/loss{n_neurons_per_hlayer}_{type(opt).__name__}_RELUDropOut04LR01BS512.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  0.8927488327026367\n",
      "Accuracy for the development test set:  0.8773090839385986\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.binary_accuracy.values[-1:][0])\n",
    "print (\"Accuracy for the development test set: \", results.val_binary_accuracy.values[-1:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.5 ],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.97],\n",
       "       [0.41],\n",
       "       [0.48],\n",
       "       [0.81],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.41],\n",
       "       [0.42],\n",
       "       [0.41]], dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validar el modelo\n",
    "dev_predictions=model.predict(X_val).round(2)\n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3627, 1)\n",
      "(3627, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dev_rounded_predictions.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_val,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 3627})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_final_test = n_instances-n_train-n_dev\n",
    "\n",
    "x_final_test = attributes.values[n_train+n_dev:n_instances]\n",
    "t_final_test = label.values[n_train+n_dev:n_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 0.6909 - binary_accuracy: 0.8379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6908889412879944, 0.8378825187683105]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_final_test, t_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(t_final_test,1))\n",
    "test_correct_predictions[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 3627})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "final_test_prediction_results=Counter(test_correct_predictions)\n",
    "final_test_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_prediction_results[True]/sum(final_test_prediction_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 1), indices imply (1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Chema\\Desktop\\MASTER\\DeepLearning\\DL\\main.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_sparse_targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(t_final_test, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m c_m\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mDataFrame(confusion_matrix(test_sparse_predictions,test_sparse_targets),columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mTrue_Cheap\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTrue_Average\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTrue_Expensive\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m c_m\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mClasses\u001b[39m\u001b[39m'\u001b[39m,[\u001b[39m'\u001b[39m\u001b[39mPred_Cheap\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPred_Average\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPred_Expensive\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chema/Desktop/MASTER/DeepLearning/DL/main.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m c_m[\u001b[39m'\u001b[39m\u001b[39mSum\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mc_m\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, numeric_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Chema\\Desktop\\MASTER\\DeepLearning\\DL\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    771\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    772\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    773\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m             copy\u001b[39m=\u001b[39m_copy,\n\u001b[0;32m    780\u001b[0m         )\n\u001b[0;32m    781\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    783\u001b[0m             data,\n\u001b[0;32m    784\u001b[0m             index,\n\u001b[0;32m    785\u001b[0m             columns,\n\u001b[0;32m    786\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    787\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    788\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    791\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\Chema\\Desktop\\MASTER\\DeepLearning\\DL\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Chema\\Desktop\\MASTER\\DeepLearning\\DL\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1, 1), indices imply (1, 3)"
     ]
    }
   ],
   "source": [
    "test_sparse_predictions = np.argmax (test_predictions,axis=1)\n",
    "test_sparse_targets = np.argmax(t_final_test, axis=1)\n",
    "print('Confusion Matrix')\n",
    "c_m=pd.DataFrame(confusion_matrix(test_sparse_predictions,test_sparse_targets),columns=['True_Cheap', 'True_Average'])\n",
    "c_m.insert(0,'Classes',['Pred_Cheap', 'Pred_Average', 'Pred_Expensive'])\n",
    "c_m['Sum']=c_m.sum(axis=1, numeric_only=True)\n",
    "c_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cheap       1.00      1.00      1.00      3627\n",
      "\n",
      "    accuracy                           1.00      3627\n",
      "   macro avg       1.00      1.00      1.00      3627\n",
      "weighted avg       1.00      1.00      1.00      3627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "classes = ['Cheap']\n",
    "print(classification_report(test_sparse_targets, test_sparse_predictions, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
