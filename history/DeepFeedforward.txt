DeepFeedforward
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.1
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 152.54603659990244
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 138.07221240003128
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999655485153198
Accuracy for the development test set: 1.0
Time: 75.65785129996948
--------------------------------------------------------------------------------------------
Epoque: 150
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999310970306396
Accuracy for the development test set: 1.0
Time: 93.38526189990807
--------------------------------------------------------------------------------------------
Epoque: 2
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9987593293190002
Accuracy for the development test set: 1.0
Time: 4.20937449997291
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 125]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 67.29340219998267
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [1000, 500, 125, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 163.58561569999438
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [250, 125]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 36.47459989995696
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [100, 20]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9997932314872742
Accuracy for the development test set: 1.0
Time: 23.689233600045554
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999655485153198
Accuracy for the development test set: 1.0
Time: 17.944123600027524
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 250
Dropout: 0.2
Neurons per layer: [50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 30.93367759999819
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 250
Dropout: 0.2
Neurons per layer: [100, 50, 25, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.858009397983551
Accuracy for the development test set: 0.8558036684989929
Time: 46.25459689996205
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8753446340560913
Accuracy for the development test set: 0.8585608005523682
Time: 100.58772860001773
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8438103199005127
Accuracy for the development test set: 0.8329197764396667
Time: 59.198380099842325
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.81782466173172
Accuracy for the development test set: 0.8141714930534363
Time: 15.579255300108343
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8242349028587341
Accuracy for the development test set: 0.8249241709709167
Time: 18.559147299965844
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9120140671730042
Accuracy for the development test set: 0.872622013092041
Time: 1148.610198300099
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [1024, 512, 256, 128, 64, 32, 16]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8374345302581787
Accuracy for the development test set: 0.826302707195282
Time: 374.4783805999905
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [512, 256, 128, 32]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8423972725868225
Accuracy for the development test set: 0.8003860116004944
Time: 212.15863870014437
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False, kernel_regularizer=keras.regularizers.l2(lr))); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8424662351608276
Accuracy for the development test set: 0.7697821855545044
Time: 157.69135749991983
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8721739649772644
Accuracy for the development test set: 0.858009397983551
Time: 295.09091320005246
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8676592111587524
Accuracy for the development test set: 0.8717948794364929
Time: 205.25598599994555
--------------------------------------------------------------------------------------------
Epoque: 400
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8864074945449829
Accuracy for the development test set: 0.8855803608894348
Time: 406.39828550000675
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8692790269851685
Accuracy for the development test set: 0.8728976845741272
Time: 208.38497300003655
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8685207962989807
Accuracy for the development test set: 0.8682106137275696
Time: 316.955052399775
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8705886602401733
Accuracy for the development test set: 0.8775847554206848
Time: 293.8743908999022
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8563206791877747
Accuracy for the development test set: 0.8497380614280701
Time: 107.99375140000484
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8723807334899902
Accuracy for the development test set: 0.8596636056900024
Time: 216.02548499999102
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8720706105232239
Accuracy for the development test set: 0.8596636056900024
Time: 201.77682389999973
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8715881109237671
Accuracy for the development test set: 0.8626964688301086
Time: 224.38327419999405
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [1024, 512, 256]
Activation: elu
Optimizer: Adam
seed = 0
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.876619815826416
Accuracy for the development test set: 0.8610422015190125
Time: 536.3358705999854
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2024
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8687276244163513
Accuracy for the development test set: 0.8701406121253967
Time: 226.68172360002063
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8703129291534424
Accuracy for the development test set: 0.8759305477142334
Time: 223.7571537999902
--------------------------------------------------------------------------------------------
Epoque: 400
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8879583477973938
Accuracy for the development test set: 0.8811690211296082
Time: 437.0507530000177
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.2
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8970568180084229
Accuracy for the development test set: 0.879514753818512
Time: 952.7770118000044
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.25
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8913702964782715
Accuracy for the development test set: 0.8839260935783386
Time: 1204.6524139999965
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.25
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8951612710952759
Accuracy for the development test set: 0.8869588971138
Time: 1061.4789835999982
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 128
Dropout: 0.25
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8821684718132019
Accuracy for the development test set: 0.8814446926116943
Time: 1183.067677500003
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 64
Dropout: 0.25
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8831334710121155
Accuracy for the development test set: 0.8830989599227905
Time: 2298.903593400006
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.25
Neurons per layer: [200, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8874413967132568
Accuracy for the development test set: 0.8836504220962524
Time: 857.7943837999992
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.25
Neurons per layer: [200, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8815136551856995
Accuracy for the development test set: 0.8866832256317139
Time: 1006.7299364999999
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.1
Batch Size: 128
Dropout: 0.25
Neurons per layer: [250, 600, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
seed = 2023
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8904742002487183
Accuracy for the development test set: 0.887510359287262
Time: 1501.0556894999972
--------------------------------------------------------------------------------------------
