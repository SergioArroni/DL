DeepFeedforward
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.1
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 152.54603659990244
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 138.07221240003128
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999655485153198
Accuracy for the development test set: 1.0
Time: 75.65785129996948
--------------------------------------------------------------------------------------------
Epoque: 150
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999310970306396
Accuracy for the development test set: 1.0
Time: 93.38526189990807
--------------------------------------------------------------------------------------------
Epoque: 2
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 75, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9987593293190002
Accuracy for the development test set: 1.0
Time: 4.20937449997291
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [500, 250, 125]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 67.29340219998267
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [1000, 500, 125, 25]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 163.58561569999438
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [250, 125]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 36.47459989995696
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.5
Neurons per layer: [100, 20]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9997932314872742
Accuracy for the development test set: 1.0
Time: 23.689233600045554
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9999655485153198
Accuracy for the development test set: 1.0
Time: 17.944123600027524
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 250
Dropout: 0.2
Neurons per layer: [50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 1.0
Accuracy for the development test set: 1.0
Time: 30.93367759999819
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 250
Dropout: 0.2
Neurons per layer: [100, 50, 25, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.858009397983551
Accuracy for the development test set: 0.8558036684989929
Time: 46.25459689996205
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8753446340560913
Accuracy for the development test set: 0.8585608005523682
Time: 100.58772860001773
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8438103199005127
Accuracy for the development test set: 0.8329197764396667
Time: 59.198380099842325
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.81782466173172
Accuracy for the development test set: 0.8141714930534363
Time: 15.579255300108343
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8242349028587341
Accuracy for the development test set: 0.8249241709709167
Time: 18.559147299965844
--------------------------------------------------------------------------------------------
Epoque: 1000
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.9120140671730042
Accuracy for the development test set: 0.872622013092041
Time: 1148.610198300099
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [1024, 512, 256, 128, 64, 32, 16]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8374345302581787
Accuracy for the development test set: 0.826302707195282
Time: 374.4783805999905
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [512, 256, 128, 32]
Activation: relu
Optimizer: Adam
--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8423972725868225
Accuracy for the development test set: 0.8003860116004944
Time: 212.15863870014437
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False, kernel_regularizer=keras.regularizers.l2(lr))); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8424662351608276
Accuracy for the development test set: 0.7697821855545044
Time: 157.69135749991983
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8721739649772644
Accuracy for the development test set: 0.858009397983551
Time: 295.09091320005246
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8676592111587524
Accuracy for the development test set: 0.8717948794364929
Time: 205.25598599994555
--------------------------------------------------------------------------------------------
Epoque: 400
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8864074945449829
Accuracy for the development test set: 0.8855803608894348
Time: 406.39828550000675
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8692790269851685
Accuracy for the development test set: 0.8728976845741272
Time: 208.38497300003655
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8685207962989807
Accuracy for the development test set: 0.8682106137275696
Time: 316.955052399775
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8705886602401733
Accuracy for the development test set: 0.8775847554206848
Time: 293.8743908999022
--------------------------------------------------------------------------------------------
Epoque: 100
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8563206791877747
Accuracy for the development test set: 0.8497380614280701
Time: 107.99375140000484
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50, 10]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8723807334899902
Accuracy for the development test set: 0.8596636056900024
Time: 216.02548499999102
--------------------------------------------------------------------------------------------
Epoque: 200
Learning Rate: 0.001
Batch Size: 512
Dropout: 0.2
Neurons per layer: [500, 250, 125, 50]
Activation: elu
Optimizer: Adam
model.add(keras.layers.Dense(neurons, kernel_initializer=he_normal, use_bias=False)); model.add(keras.layers.BatchNormalization()); model.add(keras.layers.Activation(elu)); model.add(tf.keras.layers.Dropout(tasa_dropout))--------------------------------------------------------------------------------------------
Accuracy for the training set: 0.8720706105232239
Accuracy for the development test set: 0.8596636056900024
Time: 201.77682389999973
--------------------------------------------------------------------------------------------
